{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejVADwfuIBi1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "-2jZup6ehlxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics -q"
      ],
      "metadata": {
        "id": "uhZYcWWyB2vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e701461-f5b8-4763-a459-818be721e205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.1/723.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "vm-PRbrKCcJc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8m.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gAd53lXB2xu",
        "outputId": "af6a85cf-024d-46ed-8a77-caee8b2d982f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 176MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data = \"/content/drive/MyDrive/garualytics/latest.v1i.yolov8/data.yaml\", epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdpcoRSEB23A",
        "outputId": "fff48e78-5fd3-47a2-aa9d-bd089a491856"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.35 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/drive/MyDrive/garualytics/latest.v1i.yolov8/data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train22, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25858636 parameters, 25858620 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 475/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train22', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/garualytics/latest.v1i.yolov8/train/labels.cache... 1638 images, 15 backgrounds, 0 corrupt: 100%|██████████| 1638/1638 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 588, len(boxes) = 3107. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/garualytics/latest.v1i.yolov8/valid/labels.cache... 102 images, 1 backgrounds, 0 corrupt: 100%|██████████| 102/102 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 33, len(boxes) = 276. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train22/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train22\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      7.17G     0.6838     0.4817      1.098          6        640: 100%|██████████| 103/103 [00:59<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.74it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.846      0.826      0.838      0.649\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20      7.37G     0.8677      0.674       1.22         13        640: 100%|██████████| 103/103 [00:56<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.19it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.685      0.766      0.769      0.558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      7.08G     0.9496     0.7672      1.294         16        640: 100%|██████████| 103/103 [00:55<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.688      0.751      0.738      0.516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      7.04G     0.9628      0.784      1.307         11        640: 100%|██████████| 103/103 [00:55<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.719      0.795      0.807      0.565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20      7.03G     0.9582     0.7574      1.281         11        640: 100%|██████████| 103/103 [00:54<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.819       0.83      0.824      0.583\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20      7.04G     0.9558     0.7386      1.286         14        640: 100%|██████████| 103/103 [00:54<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.88it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.817      0.824      0.842       0.59\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20      7.04G     0.9191     0.6881       1.25         11        640: 100%|██████████| 103/103 [00:54<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.844      0.844      0.843      0.619\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20      7.04G     0.8901     0.6636      1.246         17        640: 100%|██████████| 103/103 [00:54<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.899      0.851      0.867      0.617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20         7G     0.8315     0.6062      1.202         11        640: 100%|██████████| 103/103 [00:55<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.874      0.825      0.856      0.659\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20      7.04G     0.8085     0.5914      1.184         12        640: 100%|██████████| 103/103 [00:54<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.38it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.855      0.783      0.841      0.642\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      7.06G     0.7587     0.5372      1.137          6        640: 100%|██████████| 103/103 [00:57<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.17it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.867      0.814      0.864      0.674\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      7.04G     0.7266     0.5135      1.121         13        640: 100%|██████████| 103/103 [00:59<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.25it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.919      0.856      0.885      0.684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20         7G     0.7019     0.4924      1.104         10        640: 100%|██████████| 103/103 [00:55<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.904      0.863      0.881       0.69\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      7.04G     0.6844     0.4519      1.083         13        640: 100%|██████████| 103/103 [00:55<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.868      0.866      0.865      0.678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      7.04G     0.6438     0.4365      1.056          8        640: 100%|██████████| 103/103 [00:56<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.02it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        102        276      0.905      0.853      0.873      0.695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20      7.05G     0.6218     0.4302      1.041         14        640: 100%|██████████| 103/103 [00:54<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        102        276      0.899      0.866      0.879      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20      7.03G     0.5987     0.4065      1.026          8        640: 100%|██████████| 103/103 [00:54<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        102        276      0.922      0.853      0.882      0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20      7.04G     0.5719     0.3834      1.012         33        640: 100%|██████████| 103/103 [00:55<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        102        276      0.898      0.856       0.87      0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20      7.04G     0.5454     0.3674      1.004         11        640: 100%|██████████| 103/103 [00:54<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        102        276       0.94      0.856      0.886      0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      7.06G     0.5201     0.3525     0.9817         34        640:  51%|█████▏    | 53/103 [00:28<00:25,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        102        276       0.94      0.856      0.886      0.723\n",
            "            guard rail        102         38       0.86      0.553      0.593      0.403\n",
            "    road traffic cones        102        115      0.928      0.899      0.971      0.734\n",
            "           street lamp        102          9      0.997          1      0.995      0.951\n",
            "          traffic sign        102        114      0.974      0.971      0.985      0.804\n",
            "Speed: 0.8ms preprocess, 13.6ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 3])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x78fce7c7c3d0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0012583,  0.00062913,           0],\n",
              "       [          1,           1,           1, ...,     0.57789,     0.57789,           0],\n",
              "       [          1,           1,           1, ...,           1,           1,           0],\n",
              "       [          1,           1,           1, ...,    0.090005,    0.045003,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.30769,     0.30769,     0.35138, ...,           0,           0,           0],\n",
              "       [     0.6267,      0.6267,     0.69162, ...,           0,           0,           0],\n",
              "       [    0.69231,     0.69231,     0.75605, ...,           0,           0,           0],\n",
              "       [      0.875,       0.875,      0.9127, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.19847,     0.19847,      0.2434, ...,           1,           1,           1],\n",
              "       [    0.45635,     0.45635,     0.52861, ...,           1,           1,           1],\n",
              "       [    0.52941,     0.52941,     0.60778, ...,           1,           1,           1],\n",
              "       [    0.78873,     0.78873,     0.85219, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.68421,     0.68421,     0.63158, ...,           0,           0,           0],\n",
              "       [          1,           1,           1, ...,           0,           0,           0],\n",
              "       [          1,           1,           1, ...,           0,           0,           0],\n",
              "       [    0.98246,     0.98246,     0.98246, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.7392436631455392\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.40326,     0.73391,     0.95063,     0.80391])\n",
              "names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9396014080726697, 'metrics/recall(B)': 0.8556054530135184, 'metrics/mAP50(B)': 0.8860777714595551, 'metrics/mAP50-95(B)': 0.7229287622217597, 'fitness': 0.7392436631455392}\n",
              "save_dir: PosixPath('runs/detect/train22')\n",
              "speed: {'preprocess': 0.750113936031566, 'inference': 13.611688333399156, 'loss': 0.0006404577517041972, 'postprocess': 5.487893141952215}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hlGIEAoByxsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image(filename=\"/content/runs/detect/train22/confusion_matrix.png\", width=600)"
      ],
      "metadata": {
        "id": "4DF_7IN1mWVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer = YOLO (\"/content/best (5).pt\")"
      ],
      "metadata": {
        "id": "Q7Z7e7xVmWZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer.predict(\"/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images\" , save = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoGxrZ9HHE1z",
        "outputId": "05e3fd08-6ad5-4384-b607-db8a474f1b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/-18-_jpg.rf.1e7a59318cf2a362292fa4d89e3dbff7.jpg: 640x640 2 guard rails, 37.5ms\n",
            "image 2/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111133_jpg.rf.9b3002d6892717b7aa16b2f4d71998f3.jpg: 640x640 3 street lamps, 37.2ms\n",
            "image 3/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111200_jpg.rf.3b6bdaa84d46b09b83909a0ddc981648.jpg: 640x640 1 street lamp, 37.2ms\n",
            "image 4/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111226_jpg.rf.312a251ace50d148360749e88069487e.jpg: 640x640 1 street lamp, 37.1ms\n",
            "image 5/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111440_jpg.rf.602154d47999338581da5a738bddda63.jpg: 640x640 1 street lamp, 37.2ms\n",
            "image 6/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_112017_jpg.rf.6e5c50f560b619506ba05e9e4332e85d.jpg: 640x640 1 street lamp, 27.9ms\n",
            "image 7/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_112126_jpg.rf.9cec17ab7b8e2f7ebdd9bddbaa8b7229.jpg: 640x640 2 street lamps, 27.9ms\n",
            "image 8/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/9293a8f198234270_jpg.rf.9c2e3de1667de21a839e8d69ae9fca75.jpg: 640x640 1 guard rail, 27.8ms\n",
            "image 9/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/95879f30-ffb5-4d83-b7c6-629d17b284ef_jpg.rf.0551bc83c897867f6232a1ff0a12f31a.jpg: 640x640 3 guard rails, 27.9ms\n",
            "image 10/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111047_jpg.rf.bed830c291de96588019a57b66cc113b.jpg: 640x640 1 street lamp, 21.6ms\n",
            "image 11/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111328_jpg.rf.c1fd993863dc5e257a4588038e4d7088.jpg: 640x640 1 street lamp, 21.6ms\n",
            "image 12/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111558_jpg.rf.77a0446c1cffa90bc5511850c6eebe5b.jpg: 640x640 1 street lamp, 21.0ms\n",
            "image 13/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111607_jpg.rf.7f1a0c8e083be928f991995d2e45a33f.jpg: 640x640 1 street lamp, 21.0ms\n",
            "image 14/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111652_jpg.rf.245105946f2246680ae627503b3617e2.jpg: 640x640 1 street lamp, 20.2ms\n",
            "image 15/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111852_jpg.rf.7ba2018139aff8b9bd1fbacd8a893b42.jpg: 640x640 1 street lamp, 20.2ms\n",
            "image 16/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/bf58feca-2954-4ce4-9aed-6d9f825e7b4a_jpg.rf.805f92b3f813c5fa70568dd082e20db8.jpg: 640x640 2 guard rails, 20.1ms\n",
            "image 17/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-17-_jpg.rf.b2691cdebb3a7d89c01f24f1d0f1af40.jpg: 640x640 3 guard rails, 19.8ms\n",
            "image 18/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-38-_jpg.rf.91d906b234691116d1aa9b641ef56e0d.jpg: 640x640 1 traffic sign, 19.8ms\n",
            "image 19/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-4-_jpg.rf.4a65376cfc2df216e159a53fd500ab19.jpg: 640x640 4 traffic signs, 17.4ms\n",
            "image 20/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-43-_jpg.rf.c10e4fae4a207f964ac249271d8f381d.jpg: 640x640 1 traffic sign, 17.0ms\n",
            "image 21/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-44-_jpg.rf.7ebb9a45f977064f489f3380241d3f27.jpg: 640x640 (no detections), 17.0ms\n",
            "image 22/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-7-_jpg.rf.2a090dc649edc5e9399fe07fd819f21d.jpg: 640x640 1 guard rail, 16.9ms\n",
            "image 23/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-7-_jpg.rf.68443354fffc9a6d55ec9c44b9d7de7a.jpg: 640x640 5 traffic signs, 17.0ms\n",
            "image 24/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images22_jpeg_jpg.rf.8a7e509c9f90c90a463da1e117f6b857.jpg: 640x640 1 guard rail, 17.3ms\n",
            "image 25/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images23_jpeg_jpg.rf.2c74e955d1722f3711744828b3fe08a3.jpg: 640x640 3 guard rails, 17.4ms\n",
            "image 26/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images37_jpeg_jpg.rf.486c7b1a18a01229f93c2445d350c694.jpg: 640x640 1 guard rail, 17.8ms\n",
            "image 27/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images51_jpeg_jpg.rf.06032a3ff807986a8417ffb0aec4eca6.jpg: 640x640 2 guard rails, 18.2ms\n",
            "image 28/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images54_jpeg_jpg.rf.b198b3456a673fff8bb16a8ed9d73273.jpg: 640x640 1 guard rail, 18.0ms\n",
            "image 29/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images69_jpeg_jpg.rf.9066a15c80418f2432ab7d920540554f.jpg: 640x640 2 guard rails, 17.9ms\n",
            "image 30/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images_jpg.rf.53e2beb792311abe313836ca3cb7de4d.jpg: 640x640 1 traffic sign, 17.3ms\n",
            "image 31/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone101_jpg.rf.0169dcd01b187e35ec5c47f2a5149cce.jpg: 640x640 4 road traffic coness, 17.4ms\n",
            "image 32/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone101_jpg.rf.9c72b4ca8bc606f2ab6e4b2327c9447b.jpg: 640x640 2 road traffic coness, 17.7ms\n",
            "image 33/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone113_jpg.rf.2943d6517d13838aecd4c0a7cb5445c6.jpg: 640x640 3 road traffic coness, 17.6ms\n",
            "image 34/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone113_jpg.rf.cc05018681f2b3f96116bc1b67cba555.jpg: 640x640 4 road traffic coness, 17.6ms\n",
            "image 35/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone122_jpg.rf.e4e855a7c49f3b78cedb9c9e5d190268.jpg: 640x640 (no detections), 17.6ms\n",
            "image 36/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone127_jpg.rf.075a06e8fce780fc401a65fd1058ed4f.jpg: 640x640 3 road traffic coness, 17.5ms\n",
            "image 37/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone128_jpg.rf.ab2d3a0e611a956fe6233b337c8cc486.jpg: 640x640 1 road traffic cones, 17.6ms\n",
            "image 38/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone153_jpg.rf.7b9f1bc7455f74275bdf2bc30d2d025a.jpg: 640x640 1 road traffic cones, 17.7ms\n",
            "image 39/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone161_jpg.rf.ea2c6d933bac11208cf7bcbd87d675d4.jpg: 640x640 3 road traffic coness, 17.7ms\n",
            "image 40/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone166_jpg.rf.83d0f5f5f7e33440142af997c165196a.jpg: 640x640 3 road traffic coness, 17.6ms\n",
            "image 41/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone19_jpg.rf.49f7e98e38739f9da296eba2a219af09.jpg: 640x640 6 road traffic coness, 17.6ms\n",
            "image 42/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone210_jpg.rf.90a068bba283d3901afaa070e1e0c8fc.jpg: 640x640 1 road traffic cones, 17.7ms\n",
            "image 43/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone213_jpg.rf.2570f249c0637e6181c283171c3a922a.jpg: 640x640 1 road traffic cones, 18.0ms\n",
            "image 44/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone218_jpg.rf.b671e430de506366a7eec7afa56f6fbb.jpg: 640x640 1 road traffic cones, 18.0ms\n",
            "image 45/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone218_jpg.rf.f0ef353c4d898eab326f459ebada0e7c.jpg: 640x640 1 road traffic cones, 17.9ms\n",
            "image 46/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone224_jpg.rf.acb3d4a254d1049f51f2d37efc04e5c3.jpg: 640x640 8 road traffic coness, 17.6ms\n",
            "image 47/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone228_jpg.rf.714a3051c2badb7fb8b52f1308052bb0.jpg: 640x640 4 road traffic coness, 17.4ms\n",
            "image 48/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone254_jpg.rf.2c00cbd7f8d7d40989125e756772743d.jpg: 640x640 5 road traffic coness, 17.5ms\n",
            "image 49/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone254_jpg.rf.30c6695652678dc30744ef32e246bab5.jpg: 640x640 4 road traffic coness, 17.8ms\n",
            "image 50/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone25_jpg.rf.b1460a7aa7c1cd514a7af0b041677ff8.jpg: 640x640 1 road traffic cones, 17.8ms\n",
            "image 51/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone27_jpg.rf.3877d055b0cc6c00e264e9c8f7863426.jpg: 640x640 2 road traffic coness, 17.6ms\n",
            "image 52/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone290_jpg.rf.8cf515f47740d9e57a62556f65099d9c.jpg: 640x640 3 road traffic coness, 17.6ms\n",
            "image 53/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone296_jpg.rf.373420a8d5681cdbd476657c407bb98c.jpg: 640x640 2 road traffic coness, 17.7ms\n",
            "image 54/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone298_jpg.rf.5c1e80f7d0545c38c88875f1c26559c2.jpg: 640x640 2 road traffic coness, 17.6ms\n",
            "image 55/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone30_jpg.rf.e355b529cb6234e41ca42442eca44a37.jpg: 640x640 1 road traffic cones, 17.5ms\n",
            "image 56/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone33_jpg.rf.6d28586b94e369fef04ce544615c637c.jpg: 640x640 1 road traffic cones, 17.4ms\n",
            "image 57/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone44_jpg.rf.105bb3532a94f87034e6277a1e52aa7b.jpg: 640x640 5 road traffic coness, 17.8ms\n",
            "image 58/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone49_jpg.rf.5a7a18e1ec272fddf6cc408db83f0ec6.jpg: 640x640 3 road traffic coness, 17.9ms\n",
            "image 59/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone59_jpg.rf.1ec6eafc00a268782d37af35e135ac83.jpg: 640x640 1 road traffic cones, 17.6ms\n",
            "image 60/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone61_jpg.rf.510cc8528b91e70cf9fa96ad784e14fa.jpg: 640x640 4 road traffic coness, 17.5ms\n",
            "image 61/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone61_jpg.rf.f4cf37c93f915f63853d3a6939b8f5e3.jpg: 640x640 3 road traffic coness, 17.2ms\n",
            "image 62/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone65_jpg.rf.4c42a0fb577fec3a7e7664aff351b498.jpg: 640x640 2 road traffic coness, 17.0ms\n",
            "image 63/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone6_jpg.rf.19b1ef240eaa7c7d461a53a73ac48460.jpg: 640x640 1 road traffic cones, 17.0ms\n",
            "image 64/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone6_jpg.rf.5128fa27230510804a9f923d347c4035.jpg: 640x640 1 road traffic cones, 17.3ms\n",
            "image 65/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone73_jpg.rf.4d271a58475e016d5df30e3d4757314b.jpg: 640x640 1 guard rail, 1 road traffic cones, 1 traffic sign, 17.9ms\n",
            "image 66/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone73_jpg.rf.ffcbe395de91dee3f41e1d1a8715e0e9.jpg: 640x640 1 road traffic cones, 17.8ms\n",
            "image 67/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone75_jpg.rf.8b8d785c0f5d716bfdb340d1bb57d321.jpg: 640x640 3 road traffic coness, 17.5ms\n",
            "image 68/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone76_jpg.rf.4e7699b2df05cef85c9e2acbf79bd7a0.jpg: 640x640 1 road traffic cones, 17.3ms\n",
            "image 69/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone81_jpg.rf.8ed1c26363640e44d1ef7d63943bc32a.jpg: 640x640 6 road traffic coness, 17.0ms\n",
            "image 70/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone86_jpg.rf.a88f62753b61ea5aa7c09bb3d0d936aa.jpg: 640x640 2 road traffic coness, 18.0ms\n",
            "image 71/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone8_jpg.rf.815f646edf5a612687cf5568ab974743.jpg: 640x640 4 road traffic coness, 17.0ms\n",
            "image 72/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone95_jpg.rf.6a2c46328a2de919ed096af3d532014c.jpg: 640x640 2 road traffic coness, 17.6ms\n",
            "image 73/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-1811886949-2098761804-fm-253-fmt-auto-app-138-f-JPEG_webp_jpg.rf.e2d03bb5e29af41e11738d29f550cba1.jpg: 640x640 2 traffic signs, 17.8ms\n",
            "image 74/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-2039279726-4285130551-fm-253-fmt-auto-app-120-f-JPEG_webp_jpg.rf.261d21a4dee6a13947455a1b2296c629.jpg: 640x640 1 traffic sign, 17.8ms\n",
            "image 75/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-2327145301-2862418166-fm-253-fmt-auto-app-138-f-JPEG_webp_jpg.rf.3aed9477c6a5ad8ae420a3748d14986e.jpg: 640x640 4 traffic signs, 17.7ms\n",
            "image 76/76 /content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-3499193694-1018368932-fm-253-fmt-auto-app-120-f-JPEG_webp_jpg.rf.5fd7308f6fc11b53042b0dd066f25fc1.jpg: 640x640 1 traffic sign, 17.4ms\n",
            "Speed: 2.0ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[178, 151, 124],\n",
              "         [178, 151, 124],\n",
              "         [178, 151, 124],\n",
              "         ...,\n",
              "         [185, 158, 137],\n",
              "         [185, 158, 137],\n",
              "         [185, 158, 137]],\n",
              " \n",
              "        [[178, 151, 124],\n",
              "         [178, 151, 124],\n",
              "         [179, 152, 125],\n",
              "         ...,\n",
              "         [185, 158, 137],\n",
              "         [185, 158, 137],\n",
              "         [185, 158, 137]],\n",
              " \n",
              "        [[178, 151, 124],\n",
              "         [179, 152, 125],\n",
              "         [179, 152, 125],\n",
              "         ...,\n",
              "         [185, 158, 137],\n",
              "         [185, 158, 137],\n",
              "         [185, 158, 137]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 97,  96, 100],\n",
              "         [ 97,  96, 100],\n",
              "         [ 98,  97, 101],\n",
              "         ...,\n",
              "         [ 68,  95, 109],\n",
              "         [ 68,  94, 108],\n",
              "         [ 67,  93, 107]],\n",
              " \n",
              "        [[ 98,  94,  99],\n",
              "         [ 99,  95, 100],\n",
              "         [ 98,  97, 101],\n",
              "         ...,\n",
              "         [ 70,  97, 111],\n",
              "         [ 70,  96, 110],\n",
              "         [ 69,  95, 109]],\n",
              " \n",
              "        [[ 96,  92,  97],\n",
              "         [ 98,  94,  99],\n",
              "         [ 97,  96, 100],\n",
              "         ...,\n",
              "         [ 69,  96, 110],\n",
              "         [ 69,  95, 109],\n",
              "         [ 68,  94, 108]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/-18-_jpg.rf.1e7a59318cf2a362292fa4d89e3dbff7.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.1772384643554688, 'inference': 37.500619888305664, 'postprocess': 2.323150634765625},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[254, 247, 232],\n",
              "         [254, 247, 232],\n",
              "         [254, 247, 232],\n",
              "         ...,\n",
              "         [251, 222, 201],\n",
              "         [251, 222, 201],\n",
              "         [251, 222, 201]],\n",
              " \n",
              "        [[254, 247, 232],\n",
              "         [254, 247, 232],\n",
              "         [254, 247, 232],\n",
              "         ...,\n",
              "         [252, 223, 202],\n",
              "         [252, 223, 202],\n",
              "         [252, 223, 202]],\n",
              " \n",
              "        [[254, 247, 232],\n",
              "         [254, 247, 232],\n",
              "         [254, 247, 232],\n",
              "         ...,\n",
              "         [253, 224, 203],\n",
              "         [253, 224, 203],\n",
              "         [253, 224, 203]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[167, 175, 188],\n",
              "         [169, 177, 190],\n",
              "         [170, 177, 192],\n",
              "         ...,\n",
              "         [150, 168, 185],\n",
              "         [150, 166, 183],\n",
              "         [154, 172, 189]],\n",
              " \n",
              "        [[165, 174, 187],\n",
              "         [165, 174, 187],\n",
              "         [167, 176, 190],\n",
              "         ...,\n",
              "         [155, 175, 193],\n",
              "         [151, 168, 187],\n",
              "         [151, 171, 189]],\n",
              " \n",
              "        [[171, 180, 193],\n",
              "         [169, 178, 191],\n",
              "         [168, 177, 191],\n",
              "         ...,\n",
              "         [163, 183, 201],\n",
              "         [153, 173, 191],\n",
              "         [153, 173, 191]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111133_jpg.rf.9b3002d6892717b7aa16b2f4d71998f3.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.890420913696289, 'inference': 37.19377517700195, 'postprocess': 1.4450550079345703},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[239, 193, 175],\n",
              "         [239, 193, 175],\n",
              "         [239, 193, 175],\n",
              "         ...,\n",
              "         [231, 172, 146],\n",
              "         [231, 172, 146],\n",
              "         [231, 172, 146]],\n",
              " \n",
              "        [[239, 193, 175],\n",
              "         [239, 193, 175],\n",
              "         [239, 193, 175],\n",
              "         ...,\n",
              "         [231, 172, 146],\n",
              "         [231, 172, 146],\n",
              "         [231, 172, 146]],\n",
              " \n",
              "        [[239, 193, 175],\n",
              "         [239, 193, 175],\n",
              "         [239, 193, 175],\n",
              "         ...,\n",
              "         [231, 172, 146],\n",
              "         [231, 172, 146],\n",
              "         [231, 172, 146]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[163, 174, 188],\n",
              "         [163, 174, 188],\n",
              "         [165, 176, 190],\n",
              "         ...,\n",
              "         [163, 178, 194],\n",
              "         [161, 177, 193],\n",
              "         [161, 177, 193]],\n",
              " \n",
              "        [[161, 172, 186],\n",
              "         [162, 173, 187],\n",
              "         [165, 176, 190],\n",
              "         ...,\n",
              "         [164, 179, 195],\n",
              "         [167, 183, 199],\n",
              "         [171, 187, 203]],\n",
              " \n",
              "        [[153, 164, 178],\n",
              "         [159, 170, 184],\n",
              "         [167, 178, 192],\n",
              "         ...,\n",
              "         [158, 173, 189],\n",
              "         [161, 177, 193],\n",
              "         [167, 183, 199]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111200_jpg.rf.3b6bdaa84d46b09b83909a0ddc981648.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9164085388183594, 'inference': 37.21904754638672, 'postprocess': 1.6863346099853516},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[212, 158, 147],\n",
              "         [230, 176, 165],\n",
              "         [235, 182, 169],\n",
              "         ...,\n",
              "         [246, 212, 196],\n",
              "         [246, 212, 196],\n",
              "         [246, 212, 196]],\n",
              " \n",
              "        [[197, 143, 132],\n",
              "         [217, 163, 152],\n",
              "         [244, 191, 178],\n",
              "         ...,\n",
              "         [246, 212, 196],\n",
              "         [246, 212, 196],\n",
              "         [246, 212, 196]],\n",
              " \n",
              "        [[106,  52,  41],\n",
              "         [194, 140, 129],\n",
              "         [235, 181, 170],\n",
              "         ...,\n",
              "         [246, 212, 196],\n",
              "         [246, 212, 196],\n",
              "         [246, 212, 196]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[144, 155, 175],\n",
              "         [146, 157, 177],\n",
              "         [149, 160, 180],\n",
              "         ...,\n",
              "         [ 44,  53,  67],\n",
              "         [ 44,  52,  69],\n",
              "         [ 42,  52,  69]],\n",
              " \n",
              "        [[146, 157, 179],\n",
              "         [151, 162, 184],\n",
              "         [157, 168, 190],\n",
              "         ...,\n",
              "         [ 33,  40,  55],\n",
              "         [ 41,  48,  65],\n",
              "         [ 46,  54,  71]],\n",
              " \n",
              "        [[151, 162, 184],\n",
              "         [155, 166, 188],\n",
              "         [157, 168, 190],\n",
              "         ...,\n",
              "         [ 27,  34,  49],\n",
              "         [ 40,  47,  64],\n",
              "         [ 49,  56,  73]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111226_jpg.rf.312a251ace50d148360749e88069487e.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5208721160888672, 'inference': 37.142276763916016, 'postprocess': 1.3778209686279297},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[  0,  77,  50],\n",
              "         [  0,  69,  43],\n",
              "         [ 12,  61,  39],\n",
              "         ...,\n",
              "         [186, 146, 128],\n",
              "         [219, 179, 160],\n",
              "         [189, 152, 132]],\n",
              " \n",
              "        [[  0,  70,  44],\n",
              "         [  0,  65,  40],\n",
              "         [ 13,  62,  40],\n",
              "         ...,\n",
              "         [177, 134, 117],\n",
              "         [216, 176, 157],\n",
              "         [219, 179, 160]],\n",
              " \n",
              "        [[  4,  68,  46],\n",
              "         [  9,  66,  45],\n",
              "         [ 17,  63,  44],\n",
              "         ...,\n",
              "         [176, 130, 112],\n",
              "         [213, 170, 151],\n",
              "         [229, 187, 168]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[127, 142, 151],\n",
              "         [130, 145, 154],\n",
              "         [130, 145, 154],\n",
              "         ...,\n",
              "         [ 48, 123, 109],\n",
              "         [ 50, 132, 114],\n",
              "         [ 58, 146, 123]],\n",
              " \n",
              "        [[120, 135, 144],\n",
              "         [124, 139, 148],\n",
              "         [127, 142, 151],\n",
              "         ...,\n",
              "         [ 71, 135, 129],\n",
              "         [ 63, 128, 119],\n",
              "         [ 69, 135, 123]],\n",
              " \n",
              "        [[127, 142, 151],\n",
              "         [130, 145, 154],\n",
              "         [131, 146, 155],\n",
              "         ...,\n",
              "         [ 86, 144, 143],\n",
              "         [ 87, 145, 140],\n",
              "         [102, 159, 151]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_111440_jpg.rf.602154d47999338581da5a738bddda63.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.556396484375, 'inference': 37.21451759338379, 'postprocess': 1.5943050384521484},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[253, 220, 204],\n",
              "         [253, 220, 204],\n",
              "         [253, 220, 204],\n",
              "         ...,\n",
              "         [214, 166, 148],\n",
              "         [214, 166, 148],\n",
              "         [214, 166, 148]],\n",
              " \n",
              "        [[253, 220, 204],\n",
              "         [253, 220, 204],\n",
              "         [253, 220, 204],\n",
              "         ...,\n",
              "         [214, 166, 148],\n",
              "         [214, 166, 148],\n",
              "         [214, 166, 148]],\n",
              " \n",
              "        [[253, 220, 204],\n",
              "         [253, 220, 204],\n",
              "         [253, 220, 204],\n",
              "         ...,\n",
              "         [214, 166, 148],\n",
              "         [214, 166, 148],\n",
              "         [214, 166, 148]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[117, 148, 151],\n",
              "         [122, 153, 156],\n",
              "         [123, 153, 158],\n",
              "         ...,\n",
              "         [123, 136, 150],\n",
              "         [124, 137, 151],\n",
              "         [124, 137, 151]],\n",
              " \n",
              "        [[114, 145, 148],\n",
              "         [116, 147, 150],\n",
              "         [113, 145, 150],\n",
              "         ...,\n",
              "         [122, 135, 149],\n",
              "         [123, 136, 150],\n",
              "         [123, 136, 150]],\n",
              " \n",
              "        [[124, 155, 158],\n",
              "         [124, 155, 158],\n",
              "         [117, 149, 154],\n",
              "         ...,\n",
              "         [122, 135, 149],\n",
              "         [122, 135, 149],\n",
              "         [123, 136, 150]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_112017_jpg.rf.6e5c50f560b619506ba05e9e4332e85d.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5110969543457031, 'inference': 27.884244918823242, 'postprocess': 1.3587474822998047},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[251, 205, 187],\n",
              "         [251, 205, 187],\n",
              "         [251, 205, 187],\n",
              "         ...,\n",
              "         [250, 176, 150],\n",
              "         [250, 176, 150],\n",
              "         [250, 176, 150]],\n",
              " \n",
              "        [[251, 205, 187],\n",
              "         [251, 205, 187],\n",
              "         [251, 205, 187],\n",
              "         ...,\n",
              "         [250, 176, 150],\n",
              "         [250, 176, 150],\n",
              "         [250, 176, 150]],\n",
              " \n",
              "        [[251, 205, 187],\n",
              "         [251, 205, 187],\n",
              "         [251, 205, 187],\n",
              "         ...,\n",
              "         [250, 176, 150],\n",
              "         [250, 176, 150],\n",
              "         [250, 176, 150]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 62,  69,  89],\n",
              "         [ 82,  91, 111],\n",
              "         [ 85,  92, 112],\n",
              "         ...,\n",
              "         [161, 187, 217],\n",
              "         [171, 195, 225],\n",
              "         [173, 197, 227]],\n",
              " \n",
              "        [[ 77,  82, 103],\n",
              "         [ 79,  86, 106],\n",
              "         [ 75,  80, 101],\n",
              "         ...,\n",
              "         [177, 204, 231],\n",
              "         [170, 197, 224],\n",
              "         [162, 189, 216]],\n",
              " \n",
              "        [[ 67,  72,  93],\n",
              "         [ 63,  68,  89],\n",
              "         [ 67,  72,  93],\n",
              "         ...,\n",
              "         [172, 199, 226],\n",
              "         [173, 200, 227],\n",
              "         [173, 200, 227]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/20230322_112126_jpg.rf.9cec17ab7b8e2f7ebdd9bddbaa8b7229.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5056133270263672, 'inference': 27.85944938659668, 'postprocess': 1.3167858123779297},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/9293a8f198234270_jpg.rf.9c2e3de1667de21a839e8d69ae9fca75.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5521049499511719, 'inference': 27.82440185546875, 'postprocess': 1.440286636352539},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[168, 175, 162],\n",
              "         [166, 173, 160],\n",
              "         [164, 171, 158],\n",
              "         ...,\n",
              "         [168, 159, 121],\n",
              "         [173, 161, 121],\n",
              "         [175, 163, 123]],\n",
              " \n",
              "        [[166, 173, 160],\n",
              "         [164, 171, 158],\n",
              "         [162, 169, 156],\n",
              "         ...,\n",
              "         [160, 151, 113],\n",
              "         [166, 154, 114],\n",
              "         [167, 155, 115]],\n",
              " \n",
              "        [[163, 170, 155],\n",
              "         [161, 168, 153],\n",
              "         [159, 166, 151],\n",
              "         ...,\n",
              "         [153, 144, 106],\n",
              "         [159, 147, 107],\n",
              "         [160, 148, 108]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[144, 166, 164],\n",
              "         [144, 166, 164],\n",
              "         [143, 164, 162],\n",
              "         ...,\n",
              "         [147, 150, 141],\n",
              "         [148, 151, 142],\n",
              "         [148, 151, 142]],\n",
              " \n",
              "        [[145, 167, 165],\n",
              "         [144, 166, 164],\n",
              "         [143, 164, 162],\n",
              "         ...,\n",
              "         [145, 148, 139],\n",
              "         [144, 147, 138],\n",
              "         [144, 147, 138]],\n",
              " \n",
              "        [[145, 167, 165],\n",
              "         [144, 166, 164],\n",
              "         [143, 164, 162],\n",
              "         ...,\n",
              "         [143, 146, 137],\n",
              "         [142, 145, 136],\n",
              "         [141, 144, 135]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/95879f30-ffb5-4d83-b7c6-629d17b284ef_jpg.rf.0551bc83c897867f6232a1ff0a12f31a.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5711784362792969, 'inference': 27.893781661987305, 'postprocess': 1.4057159423828125},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 20,  31,  21],\n",
              "         [ 16,  27,  17],\n",
              "         [ 12,  23,  13],\n",
              "         ...,\n",
              "         [252, 210, 181],\n",
              "         [252, 210, 181],\n",
              "         [252, 210, 181]],\n",
              " \n",
              "        [[ 15,  26,  16],\n",
              "         [ 14,  25,  15],\n",
              "         [ 13,  24,  14],\n",
              "         ...,\n",
              "         [252, 210, 181],\n",
              "         [252, 210, 181],\n",
              "         [252, 210, 181]],\n",
              " \n",
              "        [[ 11,  22,  12],\n",
              "         [ 12,  23,  13],\n",
              "         [ 13,  24,  14],\n",
              "         ...,\n",
              "         [252, 210, 181],\n",
              "         [252, 210, 181],\n",
              "         [252, 210, 181]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  7,  16,   6],\n",
              "         [  7,  16,   6],\n",
              "         [  7,  16,   6],\n",
              "         ...,\n",
              "         [ 28,  30,  10],\n",
              "         [ 27,  29,   9],\n",
              "         [ 28,  30,  10]],\n",
              " \n",
              "        [[  8,  17,   7],\n",
              "         [  8,  17,   7],\n",
              "         [  8,  17,   7],\n",
              "         ...,\n",
              "         [ 31,  32,  12],\n",
              "         [ 31,  32,  12],\n",
              "         [ 32,  33,  13]],\n",
              " \n",
              "        [[  9,  18,   8],\n",
              "         [  8,  17,   7],\n",
              "         [  9,  18,   8],\n",
              "         ...,\n",
              "         [ 33,  34,  14],\n",
              "         [ 33,  34,  14],\n",
              "         [ 34,  35,  15]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111047_jpg.rf.bed830c291de96588019a57b66cc113b.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5645027160644531, 'inference': 21.55447006225586, 'postprocess': 1.4147758483886719},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[230, 205, 185],\n",
              "         [230, 205, 185],\n",
              "         [230, 205, 185],\n",
              "         ...,\n",
              "         [255, 253, 246],\n",
              "         [255, 253, 246],\n",
              "         [255, 253, 246]],\n",
              " \n",
              "        [[230, 205, 185],\n",
              "         [230, 205, 185],\n",
              "         [230, 205, 185],\n",
              "         ...,\n",
              "         [255, 253, 246],\n",
              "         [255, 253, 246],\n",
              "         [255, 253, 246]],\n",
              " \n",
              "        [[230, 205, 185],\n",
              "         [230, 205, 185],\n",
              "         [230, 205, 185],\n",
              "         ...,\n",
              "         [254, 254, 248],\n",
              "         [254, 254, 248],\n",
              "         [254, 254, 248]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 31,  40,  49],\n",
              "         [ 30,  40,  47],\n",
              "         [ 28,  38,  45],\n",
              "         ...,\n",
              "         [134, 156, 167],\n",
              "         [137, 159, 170],\n",
              "         [140, 162, 173]],\n",
              " \n",
              "        [[ 32,  40,  47],\n",
              "         [ 32,  41,  45],\n",
              "         [ 30,  39,  43],\n",
              "         ...,\n",
              "         [132, 157, 167],\n",
              "         [134, 159, 169],\n",
              "         [137, 162, 172]],\n",
              " \n",
              "        [[ 26,  35,  39],\n",
              "         [ 26,  35,  39],\n",
              "         [ 26,  35,  39],\n",
              "         ...,\n",
              "         [136, 161, 171],\n",
              "         [137, 162, 172],\n",
              "         [140, 165, 175]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111328_jpg.rf.c1fd993863dc5e257a4588038e4d7088.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5115737915039062, 'inference': 21.558046340942383, 'postprocess': 1.3418197631835938},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 211, 180],\n",
              "         [255, 211, 180],\n",
              "         [255, 211, 180],\n",
              "         ...,\n",
              "         [ 26,  17,   8],\n",
              "         [ 32,  22,  12],\n",
              "         [ 17,   7,   0]],\n",
              " \n",
              "        [[255, 211, 180],\n",
              "         [255, 211, 180],\n",
              "         [255, 211, 180],\n",
              "         ...,\n",
              "         [ 23,  14,   4],\n",
              "         [ 32,  22,  12],\n",
              "         [ 24,  14,   4]],\n",
              " \n",
              "        [[255, 211, 180],\n",
              "         [255, 211, 180],\n",
              "         [255, 211, 180],\n",
              "         ...,\n",
              "         [ 24,  15,   5],\n",
              "         [ 26,  16,   6],\n",
              "         [ 26,  14,   2]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 25,  58,  43],\n",
              "         [ 20,  53,  38],\n",
              "         [ 18,  51,  36],\n",
              "         ...,\n",
              "         [ 65,  77,  71],\n",
              "         [ 61,  73,  67],\n",
              "         [ 56,  68,  62]],\n",
              " \n",
              "        [[ 20,  56,  39],\n",
              "         [ 18,  54,  37],\n",
              "         [ 19,  55,  38],\n",
              "         ...,\n",
              "         [ 61,  74,  66],\n",
              "         [ 61,  74,  66],\n",
              "         [ 59,  72,  64]],\n",
              " \n",
              "        [[ 13,  50,  30],\n",
              "         [ 14,  51,  31],\n",
              "         [ 20,  57,  37],\n",
              "         ...,\n",
              "         [ 53,  66,  58],\n",
              "         [ 53,  66,  58],\n",
              "         [ 51,  64,  56]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111558_jpg.rf.77a0446c1cffa90bc5511850c6eebe5b.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.481771469116211, 'inference': 21.029949188232422, 'postprocess': 1.3723373413085938},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[209, 169, 134],\n",
              "         [209, 169, 134],\n",
              "         [209, 169, 134],\n",
              "         ...,\n",
              "         [247, 204, 171],\n",
              "         [247, 204, 171],\n",
              "         [247, 204, 171]],\n",
              " \n",
              "        [[209, 169, 134],\n",
              "         [209, 169, 134],\n",
              "         [209, 169, 134],\n",
              "         ...,\n",
              "         [247, 204, 171],\n",
              "         [247, 204, 171],\n",
              "         [247, 204, 171]],\n",
              " \n",
              "        [[209, 169, 134],\n",
              "         [209, 169, 134],\n",
              "         [209, 169, 134],\n",
              "         ...,\n",
              "         [247, 204, 171],\n",
              "         [247, 204, 171],\n",
              "         [247, 204, 171]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 21, 130,  98],\n",
              "         [ 33, 137, 104],\n",
              "         [ 42, 136, 102],\n",
              "         ...,\n",
              "         [ 82,  76,  57],\n",
              "         [ 77,  70,  51],\n",
              "         [ 71,  65,  46]],\n",
              " \n",
              "        [[  1, 130,  93],\n",
              "         [ 11, 132,  94],\n",
              "         [ 33, 139, 102],\n",
              "         ...,\n",
              "         [ 59,  55,  36],\n",
              "         [ 60,  54,  35],\n",
              "         [ 57,  53,  34]],\n",
              " \n",
              "        [[  0, 133,  95],\n",
              "         [  2, 131,  92],\n",
              "         [ 35, 150, 110],\n",
              "         ...,\n",
              "         [ 54,  50,  31],\n",
              "         [ 53,  49,  30],\n",
              "         [ 54,  50,  31]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111607_jpg.rf.7f1a0c8e083be928f991995d2e45a33f.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.4858245849609375, 'inference': 21.010398864746094, 'postprocess': 1.3687610626220703},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[175, 154, 133],\n",
              "         [175, 154, 133],\n",
              "         [175, 154, 133],\n",
              "         ...,\n",
              "         [235, 209, 193],\n",
              "         [235, 209, 193],\n",
              "         [235, 209, 193]],\n",
              " \n",
              "        [[175, 154, 133],\n",
              "         [175, 154, 133],\n",
              "         [175, 154, 133],\n",
              "         ...,\n",
              "         [235, 209, 193],\n",
              "         [235, 209, 193],\n",
              "         [235, 209, 193]],\n",
              " \n",
              "        [[175, 154, 133],\n",
              "         [175, 154, 133],\n",
              "         [175, 154, 133],\n",
              "         ...,\n",
              "         [235, 209, 193],\n",
              "         [235, 209, 193],\n",
              "         [235, 209, 193]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 92, 112, 123],\n",
              "         [ 92, 112, 123],\n",
              "         [ 92, 112, 123],\n",
              "         ...,\n",
              "         [ 61,  92, 115],\n",
              "         [ 55,  82, 108],\n",
              "         [ 52,  83, 106]],\n",
              " \n",
              "        [[ 92, 112, 123],\n",
              "         [ 92, 112, 123],\n",
              "         [ 92, 112, 123],\n",
              "         ...,\n",
              "         [ 90, 120, 137],\n",
              "         [ 84, 111, 131],\n",
              "         [ 81, 111, 128]],\n",
              " \n",
              "        [[ 92, 112, 123],\n",
              "         [ 92, 112, 123],\n",
              "         [ 92, 112, 123],\n",
              "         ...,\n",
              "         [122, 151, 166],\n",
              "         [119, 148, 163],\n",
              "         [119, 148, 163]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111652_jpg.rf.245105946f2246680ae627503b3617e2.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.4753341674804688, 'inference': 20.206928253173828, 'postprocess': 1.3206005096435547},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[230, 219, 181],\n",
              "         [153, 148, 109],\n",
              "         [132, 134,  98],\n",
              "         ...,\n",
              "         [252, 204, 176],\n",
              "         [252, 204, 176],\n",
              "         [252, 204, 176]],\n",
              " \n",
              "        [[244, 235, 198],\n",
              "         [169, 163, 126],\n",
              "         [136, 138, 102],\n",
              "         ...,\n",
              "         [252, 204, 176],\n",
              "         [252, 204, 176],\n",
              "         [252, 204, 176]],\n",
              " \n",
              "        [[255, 250, 215],\n",
              "         [204, 200, 165],\n",
              "         [171, 169, 135],\n",
              "         ...,\n",
              "         [252, 204, 176],\n",
              "         [252, 204, 176],\n",
              "         [252, 204, 176]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[201, 227, 233],\n",
              "         [200, 226, 232],\n",
              "         [202, 226, 232],\n",
              "         ...,\n",
              "         [ 25,  33,  32],\n",
              "         [ 26,  34,  33],\n",
              "         [ 28,  36,  35]],\n",
              " \n",
              "        [[204, 233, 238],\n",
              "         [203, 232, 237],\n",
              "         [205, 231, 237],\n",
              "         ...,\n",
              "         [ 22,  30,  29],\n",
              "         [ 26,  34,  33],\n",
              "         [ 31,  39,  38]],\n",
              " \n",
              "        [[177, 206, 211],\n",
              "         [176, 205, 210],\n",
              "         [178, 204, 210],\n",
              "         ...,\n",
              "         [ 22,  30,  29],\n",
              "         [ 30,  38,  37],\n",
              "         [ 37,  45,  44]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/IMG20230322111852_jpg.rf.7ba2018139aff8b9bd1fbacd8a893b42.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.5444755554199219, 'inference': 20.219802856445312, 'postprocess': 1.3086795806884766},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[191, 182, 172],\n",
              "         [191, 182, 172],\n",
              "         [192, 183, 173],\n",
              "         ...,\n",
              "         [ 32,  30,  30],\n",
              "         [ 32,  30,  30],\n",
              "         [ 36,  34,  34]],\n",
              " \n",
              "        [[191, 182, 172],\n",
              "         [191, 182, 172],\n",
              "         [192, 183, 173],\n",
              "         ...,\n",
              "         [ 28,  26,  26],\n",
              "         [ 28,  26,  26],\n",
              "         [ 31,  29,  29]],\n",
              " \n",
              "        [[191, 182, 172],\n",
              "         [191, 182, 172],\n",
              "         [192, 183, 173],\n",
              "         ...,\n",
              "         [ 28,  26,  26],\n",
              "         [ 28,  26,  26],\n",
              "         [ 32,  30,  30]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[119, 110, 106],\n",
              "         [117, 108, 104],\n",
              "         [114, 105, 101],\n",
              "         ...,\n",
              "         [110, 109, 111],\n",
              "         [112, 109, 111],\n",
              "         [114, 111, 113]],\n",
              " \n",
              "        [[116, 107, 103],\n",
              "         [118, 109, 105],\n",
              "         [119, 110, 106],\n",
              "         ...,\n",
              "         [114, 111, 113],\n",
              "         [111, 108, 110],\n",
              "         [110, 107, 109]],\n",
              " \n",
              "        [[109, 100,  96],\n",
              "         [116, 107, 103],\n",
              "         [122, 113, 109],\n",
              "         ...,\n",
              "         [123, 120, 122],\n",
              "         [117, 114, 116],\n",
              "         [111, 108, 110]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/bf58feca-2954-4ce4-9aed-6d9f825e7b4a_jpg.rf.805f92b3f813c5fa70568dd082e20db8.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.4700889587402344, 'inference': 20.086288452148438, 'postprocess': 1.4622211456298828},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[231, 247, 246],\n",
              "         [227, 243, 242],\n",
              "         [225, 239, 238],\n",
              "         ...,\n",
              "         [123, 119, 125],\n",
              "         [124, 120, 126],\n",
              "         [122, 118, 124]],\n",
              " \n",
              "        [[234, 250, 249],\n",
              "         [229, 245, 244],\n",
              "         [228, 242, 241],\n",
              "         ...,\n",
              "         [124, 120, 126],\n",
              "         [127, 123, 129],\n",
              "         [125, 121, 127]],\n",
              " \n",
              "        [[225, 239, 238],\n",
              "         [221, 235, 234],\n",
              "         [223, 235, 235],\n",
              "         ...,\n",
              "         [124, 120, 126],\n",
              "         [128, 124, 130],\n",
              "         [127, 123, 129]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[132, 138, 149],\n",
              "         [132, 138, 149],\n",
              "         [128, 134, 145],\n",
              "         ...,\n",
              "         [169, 165, 176],\n",
              "         [168, 164, 175],\n",
              "         [167, 163, 174]],\n",
              " \n",
              "        [[127, 133, 144],\n",
              "         [129, 135, 146],\n",
              "         [128, 134, 145],\n",
              "         ...,\n",
              "         [172, 168, 179],\n",
              "         [170, 166, 177],\n",
              "         [169, 165, 176]],\n",
              " \n",
              "        [[129, 135, 146],\n",
              "         [130, 136, 147],\n",
              "         [129, 135, 146],\n",
              "         ...,\n",
              "         [175, 171, 182],\n",
              "         [172, 168, 179],\n",
              "         [170, 166, 177]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-17-_jpg.rf.b2691cdebb3a7d89c01f24f1d0f1af40.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.485586166381836, 'inference': 19.846439361572266, 'postprocess': 1.308441162109375},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[125, 123, 123],\n",
              "         [125, 123, 123],\n",
              "         [125, 123, 123],\n",
              "         ...,\n",
              "         [226, 224, 224],\n",
              "         [224, 222, 222],\n",
              "         [223, 221, 221]],\n",
              " \n",
              "        [[125, 123, 123],\n",
              "         [125, 123, 123],\n",
              "         [125, 123, 123],\n",
              "         ...,\n",
              "         [225, 223, 223],\n",
              "         [224, 222, 222],\n",
              "         [224, 222, 222]],\n",
              " \n",
              "        [[125, 123, 123],\n",
              "         [125, 123, 123],\n",
              "         [125, 123, 123],\n",
              "         ...,\n",
              "         [225, 223, 223],\n",
              "         [224, 222, 222],\n",
              "         [224, 222, 222]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[102, 109, 118],\n",
              "         [100, 107, 116],\n",
              "         [ 97, 104, 113],\n",
              "         ...,\n",
              "         [172, 172, 184],\n",
              "         [171, 171, 183],\n",
              "         [171, 171, 183]],\n",
              " \n",
              "        [[103, 110, 119],\n",
              "         [101, 108, 117],\n",
              "         [ 96, 103, 112],\n",
              "         ...,\n",
              "         [171, 171, 183],\n",
              "         [170, 170, 182],\n",
              "         [170, 170, 182]],\n",
              " \n",
              "        [[108, 115, 124],\n",
              "         [104, 111, 120],\n",
              "         [ 97, 104, 113],\n",
              "         ...,\n",
              "         [170, 170, 182],\n",
              "         [169, 169, 181],\n",
              "         [169, 169, 181]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-38-_jpg.rf.91d906b234691116d1aa9b641ef56e0d.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9733905792236328, 'inference': 19.818544387817383, 'postprocess': 1.3628005981445312},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 253, 255],\n",
              "         [254, 251, 253],\n",
              "         [252, 249, 251],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 253, 255],\n",
              "         [255, 252, 254],\n",
              "         [253, 250, 252],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 253, 255],\n",
              "         [255, 253, 255],\n",
              "         [254, 251, 253],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         ...,\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207]],\n",
              " \n",
              "        [[ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         ...,\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207]],\n",
              " \n",
              "        [[ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         ...,\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207],\n",
              "         [ 40,   6, 207]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-4-_jpg.rf.4a65376cfc2df216e159a53fd500ab19.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0956993103027344, 'inference': 17.423629760742188, 'postprocess': 1.2958049774169922},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [ 56,  63,  60],\n",
              "         [ 54,  61,  58],\n",
              "         [ 57,  64,  61]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [ 59,  66,  63],\n",
              "         [ 56,  63,  60],\n",
              "         [ 58,  65,  62]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [ 70,  77,  74],\n",
              "         [ 68,  75,  72],\n",
              "         [ 70,  77,  74]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[134, 150, 157],\n",
              "         [134, 150, 157],\n",
              "         [135, 151, 158],\n",
              "         ...,\n",
              "         [ 36,  70,  69],\n",
              "         [ 37,  71,  70],\n",
              "         [ 37,  71,  70]],\n",
              " \n",
              "        [[138, 154, 161],\n",
              "         [138, 154, 161],\n",
              "         [138, 154, 161],\n",
              "         ...,\n",
              "         [ 38,  72,  71],\n",
              "         [ 38,  72,  71],\n",
              "         [ 37,  71,  70]],\n",
              " \n",
              "        [[141, 157, 164],\n",
              "         [140, 156, 163],\n",
              "         [140, 156, 163],\n",
              "         ...,\n",
              "         [ 40,  74,  73],\n",
              "         [ 40,  74,  73],\n",
              "         [ 39,  73,  72]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-43-_jpg.rf.c10e4fae4a207f964ac249271d8f381d.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.215862274169922, 'inference': 17.043113708496094, 'postprocess': 1.348257064819336},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[253, 245, 238],\n",
              "         [253, 245, 238],\n",
              "         [253, 245, 238],\n",
              "         ...,\n",
              "         [136, 131, 130],\n",
              "         [134, 129, 128],\n",
              "         [133, 128, 127]],\n",
              " \n",
              "        [[253, 245, 238],\n",
              "         [253, 245, 238],\n",
              "         [253, 245, 238],\n",
              "         ...,\n",
              "         [135, 130, 129],\n",
              "         [133, 128, 127],\n",
              "         [132, 127, 126]],\n",
              " \n",
              "        [[253, 245, 238],\n",
              "         [253, 245, 238],\n",
              "         [253, 245, 238],\n",
              "         ...,\n",
              "         [137, 132, 131],\n",
              "         [134, 129, 128],\n",
              "         [134, 129, 128]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[250, 254, 255],\n",
              "         [250, 254, 255],\n",
              "         [250, 254, 255],\n",
              "         ...,\n",
              "         [182, 182, 182],\n",
              "         [186, 186, 186],\n",
              "         [189, 189, 189]],\n",
              " \n",
              "        [[251, 255, 255],\n",
              "         [251, 255, 255],\n",
              "         [251, 255, 255],\n",
              "         ...,\n",
              "         [183, 183, 183],\n",
              "         [186, 186, 186],\n",
              "         [189, 189, 189]],\n",
              " \n",
              "        [[249, 253, 254],\n",
              "         [249, 253, 254],\n",
              "         [249, 253, 254],\n",
              "         ...,\n",
              "         [183, 183, 183],\n",
              "         [187, 187, 187],\n",
              "         [190, 190, 190]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-44-_jpg.rf.7ebb9a45f977064f489f3380241d3f27.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0270347595214844, 'inference': 17.01045036315918, 'postprocess': 0.6005764007568359},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 77, 111, 105],\n",
              "         [ 78, 112, 106],\n",
              "         [ 74, 108, 102],\n",
              "         ...,\n",
              "         [ 20,  65,  56],\n",
              "         [ 15,  58,  49],\n",
              "         [ 15,  58,  49]],\n",
              " \n",
              "        [[ 76, 110, 104],\n",
              "         [ 77, 111, 105],\n",
              "         [ 73, 107, 101],\n",
              "         ...,\n",
              "         [ 17,  62,  53],\n",
              "         [ 12,  55,  46],\n",
              "         [ 11,  54,  45]],\n",
              " \n",
              "        [[ 73, 109, 103],\n",
              "         [ 74, 110, 104],\n",
              "         [ 70, 106, 100],\n",
              "         ...,\n",
              "         [ 20,  65,  56],\n",
              "         [ 19,  62,  53],\n",
              "         [ 18,  59,  51]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[154, 158, 159],\n",
              "         [154, 158, 159],\n",
              "         [147, 151, 152],\n",
              "         ...,\n",
              "         [ 91, 102, 106],\n",
              "         [ 91, 102, 106],\n",
              "         [ 91, 102, 106]],\n",
              " \n",
              "        [[160, 164, 165],\n",
              "         [159, 163, 164],\n",
              "         [151, 155, 156],\n",
              "         ...,\n",
              "         [ 96, 107, 111],\n",
              "         [ 95, 106, 110],\n",
              "         [ 94, 105, 109]],\n",
              " \n",
              "        [[159, 163, 164],\n",
              "         [158, 162, 163],\n",
              "         [150, 154, 155],\n",
              "         ...,\n",
              "         [ 97, 108, 112],\n",
              "         [ 95, 106, 110],\n",
              "         [ 94, 105, 109]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-7-_jpg.rf.2a090dc649edc5e9399fe07fd819f21d.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.131223678588867, 'inference': 16.949176788330078, 'postprocess': 1.3365745544433594},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         ...,\n",
              "         [ 62,  62,  62],\n",
              "         [ 62,  62,  62],\n",
              "         [ 62,  62,  62]],\n",
              " \n",
              "        [[121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         ...,\n",
              "         [ 61,  61,  61],\n",
              "         [ 62,  62,  62],\n",
              "         [ 62,  62,  62]],\n",
              " \n",
              "        [[121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         ...,\n",
              "         [ 61,  61,  61],\n",
              "         [ 61,  61,  61],\n",
              "         [ 62,  62,  62]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 95,  95,  95],\n",
              "         [ 97,  97,  97],\n",
              "         [100, 100, 100],\n",
              "         ...,\n",
              "         [ 82,  82,  82],\n",
              "         [ 78,  78,  78],\n",
              "         [ 76,  76,  76]],\n",
              " \n",
              "        [[ 94,  94,  94],\n",
              "         [ 97,  97,  97],\n",
              "         [100, 100, 100],\n",
              "         ...,\n",
              "         [ 85,  85,  85],\n",
              "         [ 81,  81,  81],\n",
              "         [ 79,  79,  79]],\n",
              " \n",
              "        [[ 94,  94,  94],\n",
              "         [ 97,  97,  97],\n",
              "         [100, 100, 100],\n",
              "         ...,\n",
              "         [ 84,  84,  84],\n",
              "         [ 81,  81,  81],\n",
              "         [ 78,  78,  78]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images-7-_jpg.rf.68443354fffc9a6d55ec9c44b9d7de7a.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9533634185791016, 'inference': 17.031431198120117, 'postprocess': 1.3170242309570312},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 49,  60,  68],\n",
              "         [ 51,  62,  70],\n",
              "         [ 53,  64,  72],\n",
              "         ...,\n",
              "         [206, 219, 241],\n",
              "         [206, 219, 241],\n",
              "         [206, 219, 241]],\n",
              " \n",
              "        [[ 49,  60,  68],\n",
              "         [ 51,  62,  70],\n",
              "         [ 54,  65,  73],\n",
              "         ...,\n",
              "         [206, 219, 241],\n",
              "         [206, 219, 241],\n",
              "         [206, 219, 241]],\n",
              " \n",
              "        [[ 50,  61,  69],\n",
              "         [ 52,  63,  71],\n",
              "         [ 54,  65,  73],\n",
              "         ...,\n",
              "         [206, 219, 241],\n",
              "         [206, 219, 241],\n",
              "         [206, 219, 241]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[107, 102, 101],\n",
              "         [106, 101, 100],\n",
              "         [103,  98,  97],\n",
              "         ...,\n",
              "         [110, 101,  98],\n",
              "         [112, 103, 100],\n",
              "         [113, 104, 101]],\n",
              " \n",
              "        [[108, 103, 102],\n",
              "         [107, 102, 101],\n",
              "         [104,  99,  98],\n",
              "         ...,\n",
              "         [111, 102,  99],\n",
              "         [115, 106, 103],\n",
              "         [117, 108, 105]],\n",
              " \n",
              "        [[109, 104, 103],\n",
              "         [107, 102, 101],\n",
              "         [104,  99,  98],\n",
              "         ...,\n",
              "         [105,  96,  93],\n",
              "         [106,  97,  94],\n",
              "         [107,  98,  95]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images22_jpeg_jpg.rf.8a7e509c9f90c90a463da1e117f6b857.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.4089813232421875, 'inference': 17.305850982666016, 'postprocess': 1.4185905456542969},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[124, 114,  97],\n",
              "         [123, 113,  96],\n",
              "         [121, 111,  94],\n",
              "         ...,\n",
              "         [ 34,  34,  34],\n",
              "         [ 32,  32,  32],\n",
              "         [ 30,  30,  30]],\n",
              " \n",
              "        [[124, 114,  97],\n",
              "         [122, 112,  95],\n",
              "         [120, 110,  93],\n",
              "         ...,\n",
              "         [ 36,  36,  36],\n",
              "         [ 36,  36,  36],\n",
              "         [ 36,  36,  36]],\n",
              " \n",
              "        [[123, 113,  96],\n",
              "         [122, 112,  95],\n",
              "         [120, 110,  93],\n",
              "         ...,\n",
              "         [ 40,  40,  40],\n",
              "         [ 43,  43,  43],\n",
              "         [ 45,  45,  45]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[120, 120, 120],\n",
              "         [120, 120, 120],\n",
              "         [120, 120, 120],\n",
              "         ...,\n",
              "         [175, 184, 187],\n",
              "         [175, 184, 188],\n",
              "         [174, 183, 187]],\n",
              " \n",
              "        [[121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         ...,\n",
              "         [176, 185, 188],\n",
              "         [176, 185, 189],\n",
              "         [174, 183, 187]],\n",
              " \n",
              "        [[121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         [121, 121, 121],\n",
              "         ...,\n",
              "         [177, 186, 189],\n",
              "         [177, 186, 190],\n",
              "         [175, 184, 188]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images23_jpeg_jpg.rf.2c74e955d1722f3711744828b3fe08a3.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.023458480834961, 'inference': 17.40550994873047, 'postprocess': 1.3632774353027344},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[186, 111,   0],\n",
              "         [188, 113,   0],\n",
              "         [190, 118,   0],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[189, 114,   0],\n",
              "         [190, 115,   0],\n",
              "         [191, 119,   1],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[192, 117,   1],\n",
              "         [193, 118,   2],\n",
              "         [192, 120,   2],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  8,  32,  14],\n",
              "         [ 15,  39,  21],\n",
              "         [ 25,  49,  31],\n",
              "         ...,\n",
              "         [129, 125, 114],\n",
              "         [131, 127, 116],\n",
              "         [134, 130, 119]],\n",
              " \n",
              "        [[  8,  32,  14],\n",
              "         [ 15,  39,  21],\n",
              "         [ 25,  49,  31],\n",
              "         ...,\n",
              "         [131, 127, 116],\n",
              "         [132, 128, 117],\n",
              "         [136, 132, 121]],\n",
              " \n",
              "        [[  8,  32,  14],\n",
              "         [ 15,  39,  21],\n",
              "         [ 25,  49,  31],\n",
              "         ...,\n",
              "         [133, 129, 118],\n",
              "         [134, 130, 119],\n",
              "         [138, 134, 123]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images37_jpeg_jpg.rf.486c7b1a18a01229f93c2445d350c694.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.028942108154297, 'inference': 17.78388023376465, 'postprocess': 1.3756752014160156},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 24,  20,  19],\n",
              "         [ 21,  17,  16],\n",
              "         [ 18,  14,  13],\n",
              "         ...,\n",
              "         [ 77,  84,  93],\n",
              "         [ 79,  86,  95],\n",
              "         [ 81,  88,  97]],\n",
              " \n",
              "        [[ 24,  20,  19],\n",
              "         [ 22,  18,  17],\n",
              "         [ 19,  15,  14],\n",
              "         ...,\n",
              "         [ 77,  84,  93],\n",
              "         [ 79,  86,  95],\n",
              "         [ 81,  88,  97]],\n",
              " \n",
              "        [[ 25,  21,  20],\n",
              "         [ 23,  19,  18],\n",
              "         [ 20,  16,  15],\n",
              "         ...,\n",
              "         [ 72,  79,  88],\n",
              "         [ 72,  79,  88],\n",
              "         [ 73,  80,  89]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 78,  78,  48],\n",
              "         [ 78,  78,  48],\n",
              "         [ 78,  78,  48],\n",
              "         ...,\n",
              "         [212, 217, 216],\n",
              "         [212, 217, 216],\n",
              "         [212, 217, 216]],\n",
              " \n",
              "        [[ 79,  79,  49],\n",
              "         [ 79,  79,  49],\n",
              "         [ 79,  79,  49],\n",
              "         ...,\n",
              "         [212, 217, 216],\n",
              "         [212, 217, 216],\n",
              "         [212, 217, 216]],\n",
              " \n",
              "        [[ 79,  79,  49],\n",
              "         [ 79,  79,  49],\n",
              "         [ 79,  79,  49],\n",
              "         ...,\n",
              "         [212, 217, 216],\n",
              "         [212, 217, 216],\n",
              "         [212, 217, 216]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images51_jpeg_jpg.rf.06032a3ff807986a8417ffb0aec4eca6.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9731521606445312, 'inference': 18.17798614501953, 'postprocess': 1.5025138854980469},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[138, 140, 140],\n",
              "         [139, 141, 141],\n",
              "         [139, 141, 141],\n",
              "         ...,\n",
              "         [ 85, 164, 151],\n",
              "         [ 83, 162, 149],\n",
              "         [ 81, 160, 147]],\n",
              " \n",
              "        [[139, 141, 141],\n",
              "         [139, 141, 141],\n",
              "         [140, 142, 142],\n",
              "         ...,\n",
              "         [ 85, 164, 151],\n",
              "         [ 83, 162, 149],\n",
              "         [ 81, 160, 147]],\n",
              " \n",
              "        [[140, 142, 142],\n",
              "         [140, 142, 142],\n",
              "         [140, 142, 142],\n",
              "         ...,\n",
              "         [ 84, 163, 150],\n",
              "         [ 83, 162, 149],\n",
              "         [ 82, 161, 148]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[105, 108, 113],\n",
              "         [111, 114, 119],\n",
              "         [116, 119, 124],\n",
              "         ...,\n",
              "         [249, 243, 236],\n",
              "         [248, 242, 235],\n",
              "         [247, 241, 234]],\n",
              " \n",
              "        [[104, 107, 112],\n",
              "         [111, 114, 119],\n",
              "         [117, 120, 125],\n",
              "         ...,\n",
              "         [249, 243, 236],\n",
              "         [248, 242, 235],\n",
              "         [247, 241, 234]],\n",
              " \n",
              "        [[104, 107, 112],\n",
              "         [111, 114, 119],\n",
              "         [117, 120, 125],\n",
              "         ...,\n",
              "         [249, 243, 236],\n",
              "         [248, 242, 235],\n",
              "         [247, 241, 234]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images54_jpeg_jpg.rf.b198b3456a673fff8bb16a8ed9d73273.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0847320556640625, 'inference': 17.960786819458008, 'postprocess': 2.104043960571289},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[53, 53, 53],\n",
              "         [53, 53, 53],\n",
              "         [54, 54, 54],\n",
              "         ...,\n",
              "         [45, 48, 46],\n",
              "         [43, 48, 46],\n",
              "         [42, 47, 45]],\n",
              " \n",
              "        [[53, 53, 53],\n",
              "         [54, 54, 54],\n",
              "         [54, 54, 54],\n",
              "         ...,\n",
              "         [43, 46, 44],\n",
              "         [40, 45, 43],\n",
              "         [39, 44, 42]],\n",
              " \n",
              "        [[56, 56, 56],\n",
              "         [57, 57, 57],\n",
              "         [57, 57, 57],\n",
              "         ...,\n",
              "         [40, 43, 41],\n",
              "         [38, 43, 41],\n",
              "         [36, 41, 39]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[67, 91, 91],\n",
              "         [54, 78, 78],\n",
              "         [32, 56, 56],\n",
              "         ...,\n",
              "         [87, 87, 93],\n",
              "         [87, 87, 93],\n",
              "         [87, 87, 93]],\n",
              " \n",
              "        [[54, 78, 78],\n",
              "         [46, 70, 70],\n",
              "         [29, 53, 53],\n",
              "         ...,\n",
              "         [87, 87, 93],\n",
              "         [88, 88, 94],\n",
              "         [88, 88, 94]],\n",
              " \n",
              "        [[49, 73, 73],\n",
              "         [43, 67, 67],\n",
              "         [31, 55, 55],\n",
              "         ...,\n",
              "         [87, 87, 93],\n",
              "         [88, 88, 94],\n",
              "         [88, 88, 94]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images69_jpeg_jpg.rf.9066a15c80418f2432ab7d920540554f.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.227306365966797, 'inference': 17.879247665405273, 'postprocess': 1.535654067993164},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         [251, 251, 251],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              " \n",
              "        [[252, 252, 252],\n",
              "         [252, 252, 252],\n",
              "         [252, 252, 252],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              " \n",
              "        [[253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [251, 248, 250],\n",
              "         [251, 248, 250],\n",
              "         [250, 247, 249]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 251, 253],\n",
              "         [254, 251, 253],\n",
              "         [254, 251, 253]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [255, 253, 255],\n",
              "         [255, 253, 255],\n",
              "         [255, 253, 255]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/images_jpg.rf.53e2beb792311abe313836ca3cb7de4d.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.29644775390625, 'inference': 17.319202423095703, 'postprocess': 1.6427040100097656},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 34,  28,  17],\n",
              "         [ 31,  25,  14],\n",
              "         [ 41,  35,  24],\n",
              "         ...,\n",
              "         [151, 160, 147],\n",
              "         [151, 160, 147],\n",
              "         [151, 160, 147]],\n",
              " \n",
              "        [[ 39,  33,  22],\n",
              "         [ 30,  24,  13],\n",
              "         [ 36,  30,  19],\n",
              "         ...,\n",
              "         [151, 160, 147],\n",
              "         [151, 160, 147],\n",
              "         [151, 160, 147]],\n",
              " \n",
              "        [[ 43,  37,  24],\n",
              "         [ 29,  23,  10],\n",
              "         [ 30,  24,  11],\n",
              "         ...,\n",
              "         [151, 160, 147],\n",
              "         [151, 160, 147],\n",
              "         [151, 160, 147]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[170, 166, 171],\n",
              "         [169, 165, 170],\n",
              "         [160, 156, 161],\n",
              "         ...,\n",
              "         [145, 149, 150],\n",
              "         [156, 160, 161],\n",
              "         [162, 166, 167]],\n",
              " \n",
              "        [[187, 183, 188],\n",
              "         [182, 178, 183],\n",
              "         [163, 159, 164],\n",
              "         ...,\n",
              "         [141, 145, 146],\n",
              "         [152, 156, 157],\n",
              "         [168, 172, 173]],\n",
              " \n",
              "        [[195, 191, 196],\n",
              "         [190, 186, 191],\n",
              "         [165, 161, 166],\n",
              "         ...,\n",
              "         [147, 151, 152],\n",
              "         [168, 172, 173],\n",
              "         [200, 204, 205]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone101_jpg.rf.0169dcd01b187e35ec5c47f2a5149cce.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.4137496948242188, 'inference': 17.354249954223633, 'postprocess': 1.57928466796875},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[192, 188, 193],\n",
              "         [186, 182, 187],\n",
              "         [165, 161, 166],\n",
              "         ...,\n",
              "         [169, 172, 176],\n",
              "         [163, 166, 170],\n",
              "         [158, 161, 165]],\n",
              " \n",
              "        [[173, 169, 174],\n",
              "         [179, 175, 180],\n",
              "         [161, 157, 162],\n",
              "         ...,\n",
              "         [166, 169, 173],\n",
              "         [166, 169, 173],\n",
              "         [167, 170, 174]],\n",
              " \n",
              "        [[136, 132, 137],\n",
              "         [167, 163, 168],\n",
              "         [161, 157, 162],\n",
              "         ...,\n",
              "         [165, 168, 172],\n",
              "         [172, 175, 179],\n",
              "         [179, 182, 186]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone101_jpg.rf.9c72b4ca8bc606f2ab6e4b2327c9447b.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.307415008544922, 'inference': 17.711877822875977, 'postprocess': 1.5418529510498047},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[122, 126, 144],\n",
              "         [109, 116, 133],\n",
              "         [105, 112, 129],\n",
              "         ...,\n",
              "         [109, 122, 138],\n",
              "         [108, 121, 137],\n",
              "         [106, 119, 135]],\n",
              " \n",
              "        [[111, 115, 133],\n",
              "         [108, 115, 132],\n",
              "         [108, 115, 132],\n",
              "         ...,\n",
              "         [110, 123, 139],\n",
              "         [108, 121, 137],\n",
              "         [106, 119, 135]],\n",
              " \n",
              "        [[ 95,  99, 117],\n",
              "         [110, 117, 134],\n",
              "         [111, 118, 135],\n",
              "         ...,\n",
              "         [110, 123, 139],\n",
              "         [107, 120, 136],\n",
              "         [104, 117, 133]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone113_jpg.rf.2943d6517d13838aecd4c0a7cb5445c6.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.172708511352539, 'inference': 17.595291137695312, 'postprocess': 1.5006065368652344},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 82,  86,  97],\n",
              "         [ 83,  87,  98],\n",
              "         [ 86,  90, 101],\n",
              "         ...,\n",
              "         [ 53,  65,  67],\n",
              "         [ 55,  67,  67],\n",
              "         [ 57,  69,  69]],\n",
              " \n",
              "        [[ 37,  41,  52],\n",
              "         [ 36,  42,  53],\n",
              "         [ 39,  43,  54],\n",
              "         ...,\n",
              "         [ 70,  82,  84],\n",
              "         [ 72,  84,  86],\n",
              "         [ 73,  85,  85]],\n",
              " \n",
              "        [[ 27,  33,  44],\n",
              "         [ 25,  34,  44],\n",
              "         [ 27,  33,  44],\n",
              "         ...,\n",
              "         [ 90, 102, 106],\n",
              "         [ 90, 102, 106],\n",
              "         [ 91, 104, 106]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[112, 124, 142],\n",
              "         [108, 120, 138],\n",
              "         [102, 114, 132],\n",
              "         ...,\n",
              "         [105, 115, 132],\n",
              "         [109, 119, 136],\n",
              "         [111, 121, 138]],\n",
              " \n",
              "        [[110, 122, 140],\n",
              "         [105, 117, 135],\n",
              "         [ 98, 110, 128],\n",
              "         ...,\n",
              "         [102, 112, 129],\n",
              "         [107, 117, 134],\n",
              "         [110, 120, 137]],\n",
              " \n",
              "        [[109, 121, 139],\n",
              "         [104, 116, 134],\n",
              "         [ 97, 109, 127],\n",
              "         ...,\n",
              "         [ 98, 108, 125],\n",
              "         [105, 115, 132],\n",
              "         [109, 119, 136]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone113_jpg.rf.cc05018681f2b3f96116bc1b67cba555.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.259492874145508, 'inference': 17.616748809814453, 'postprocess': 1.6703605651855469},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 40,  36,  31],\n",
              "         [ 43,  39,  34],\n",
              "         [ 35,  31,  26],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 35,  31,  26],\n",
              "         [ 42,  38,  33],\n",
              "         [ 40,  36,  31],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 36,  32,  27],\n",
              "         [ 45,  41,  36],\n",
              "         [ 45,  41,  36],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 71,  78, 158],\n",
              "         [ 69,  76, 156],\n",
              "         [ 68,  75, 155]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 71,  78, 158],\n",
              "         [ 69,  76, 156],\n",
              "         [ 67,  74, 154]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 70,  77, 157],\n",
              "         [ 69,  76, 156],\n",
              "         [ 67,  74, 154]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone122_jpg.rf.e4e855a7c49f3b78cedb9c9e5d190268.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.187013626098633, 'inference': 17.5631046295166, 'postprocess': 0.6451606750488281},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [246, 246, 246],\n",
              "         [235, 235, 235],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[240, 240, 240],\n",
              "         [250, 250, 250],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[224, 224, 224],\n",
              "         [253, 253, 253],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone127_jpg.rf.075a06e8fce780fc401a65fd1058ed4f.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.2149085998535156, 'inference': 17.521142959594727, 'postprocess': 1.447439193725586},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[215, 233, 196],\n",
              "         [176, 194, 157],\n",
              "         [105, 122,  88],\n",
              "         ...,\n",
              "         [154, 179, 141],\n",
              "         [178, 202, 168],\n",
              "         [ 48,  72,  38]],\n",
              " \n",
              "        [[197, 215, 178],\n",
              "         [194, 212, 175],\n",
              "         [166, 183, 149],\n",
              "         ...,\n",
              "         [155, 180, 142],\n",
              "         [174, 198, 164],\n",
              "         [ 61,  85,  51]],\n",
              " \n",
              "        [[166, 185, 146],\n",
              "         [189, 208, 169],\n",
              "         [196, 214, 177],\n",
              "         ...,\n",
              "         [175, 200, 162],\n",
              "         [167, 191, 157],\n",
              "         [ 54,  78,  44]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[191, 188, 190],\n",
              "         [193, 190, 192],\n",
              "         [195, 192, 194],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[203, 200, 202],\n",
              "         [202, 199, 201],\n",
              "         [201, 198, 200],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 75,  72,  74],\n",
              "         [ 48,  45,  47],\n",
              "         [ 18,  15,  17],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone128_jpg.rf.ab2d3a0e611a956fe6233b337c8cc486.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.1588802337646484, 'inference': 17.55046844482422, 'postprocess': 1.4925003051757812},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[102, 103, 123],\n",
              "         [ 92,  95, 116],\n",
              "         [ 87,  92, 117],\n",
              "         ...,\n",
              "         [ 86,  96, 136],\n",
              "         [ 82,  91, 135],\n",
              "         [ 66,  75, 119]],\n",
              " \n",
              "        [[122, 121, 141],\n",
              "         [110, 111, 132],\n",
              "         [ 99, 103, 128],\n",
              "         ...,\n",
              "         [ 73,  84, 122],\n",
              "         [ 67,  77, 117],\n",
              "         [ 52,  61, 104]],\n",
              " \n",
              "        [[114, 108, 131],\n",
              "         [105, 101, 126],\n",
              "         [ 97,  95, 124],\n",
              "         ...,\n",
              "         [ 64,  74, 108],\n",
              "         [ 66,  75, 112],\n",
              "         [ 57,  66, 103]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 84,  73,  83],\n",
              "         [ 91,  80,  88],\n",
              "         [ 88,  79,  89],\n",
              "         ...,\n",
              "         [ 43,  29,  31],\n",
              "         [101,  87,  89],\n",
              "         [111,  97,  99]],\n",
              " \n",
              "        [[ 71,  59,  71],\n",
              "         [ 74,  63,  73],\n",
              "         [107,  97, 109],\n",
              "         ...,\n",
              "         [105,  91,  93],\n",
              "         [ 73,  59,  61],\n",
              "         [ 72,  58,  60]],\n",
              " \n",
              "        [[ 81,  69,  81],\n",
              "         [ 83,  71,  83],\n",
              "         [ 43,  33,  45],\n",
              "         ...,\n",
              "         [125, 111, 113],\n",
              "         [ 79,  65,  67],\n",
              "         [102,  88,  90]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone153_jpg.rf.7b9f1bc7455f74275bdf2bc30d2d025a.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.1638870239257812, 'inference': 17.68207550048828, 'postprocess': 1.4133453369140625},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone161_jpg.rf.ea2c6d933bac11208cf7bcbd87d675d4.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.017498016357422, 'inference': 17.68207550048828, 'postprocess': 1.4176368713378906},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [6, 1, 2],\n",
              "         [2, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [4, 2, 2],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [4, 2, 2],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone166_jpg.rf.83d0f5f5f7e33440142af997c165196a.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.094268798828125, 'inference': 17.569780349731445, 'postprocess': 1.4340877532958984},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[173, 148, 144],\n",
              "         [152, 127, 123],\n",
              "         [111,  89,  84],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[171, 144, 140],\n",
              "         [183, 156, 152],\n",
              "         [186, 161, 157],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[167, 136, 133],\n",
              "         [181, 150, 147],\n",
              "         [179, 150, 146],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [173, 156, 147],\n",
              "         [173, 156, 147],\n",
              "         [172, 157, 148]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [168, 155, 147],\n",
              "         [169, 156, 148],\n",
              "         [167, 156, 148]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [163, 152, 144],\n",
              "         [164, 153, 145],\n",
              "         [163, 154, 145]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone19_jpg.rf.49f7e98e38739f9da296eba2a219af09.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.2590160369873047, 'inference': 17.611026763916016, 'postprocess': 1.5413761138916016},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[244, 244, 244],\n",
              "         [215, 215, 215],\n",
              "         [171, 171, 171],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[238, 238, 238],\n",
              "         [241, 241, 241],\n",
              "         [247, 247, 247],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone210_jpg.rf.90a068bba283d3901afaa070e1e0c8fc.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0437240600585938, 'inference': 17.67277717590332, 'postprocess': 1.4095306396484375},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[252, 252, 252],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [213, 211, 211],\n",
              "         [211, 209, 209],\n",
              "         [209, 207, 207]],\n",
              " \n",
              "        [[233, 233, 233],\n",
              "         [253, 253, 253],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [211, 209, 209],\n",
              "         [209, 207, 207],\n",
              "         [208, 206, 206]],\n",
              " \n",
              "        [[203, 203, 203],\n",
              "         [251, 251, 251],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [207, 205, 205],\n",
              "         [207, 205, 205],\n",
              "         [206, 204, 204]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone213_jpg.rf.2570f249c0637e6181c283171c3a922a.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.062559127807617, 'inference': 17.98868179321289, 'postprocess': 1.4121532440185547},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone218_jpg.rf.b671e430de506366a7eec7afa56f6fbb.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9469261169433594, 'inference': 18.01276206970215, 'postprocess': 1.5444755554199219},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[245, 245, 245],\n",
              "         [255, 255, 255],\n",
              "         [248, 248, 248],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[220, 220, 220],\n",
              "         [255, 255, 255],\n",
              "         [251, 251, 251],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[183, 183, 183],\n",
              "         [254, 254, 254],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone218_jpg.rf.f0ef353c4d898eab326f459ebada0e7c.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9235610961914062, 'inference': 17.887592315673828, 'postprocess': 1.413106918334961},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[125, 140, 149],\n",
              "         [123, 138, 147],\n",
              "         [119, 134, 143],\n",
              "         ...,\n",
              "         [ 79, 139, 133],\n",
              "         [ 79, 137, 132],\n",
              "         [ 78, 136, 131]],\n",
              " \n",
              "        [[143, 155, 167],\n",
              "         [141, 153, 163],\n",
              "         [138, 150, 162],\n",
              "         ...,\n",
              "         [ 79, 139, 133],\n",
              "         [ 78, 136, 131],\n",
              "         [ 78, 136, 131]],\n",
              " \n",
              "        [[163, 172, 186],\n",
              "         [162, 171, 184],\n",
              "         [160, 169, 183],\n",
              "         ...,\n",
              "         [ 78, 138, 132],\n",
              "         [ 77, 135, 130],\n",
              "         [ 76, 134, 129]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[113, 104, 101],\n",
              "         [114, 105, 102],\n",
              "         [114, 105, 102],\n",
              "         ...,\n",
              "         [109, 107, 107],\n",
              "         [109, 107, 107],\n",
              "         [109, 107, 107]],\n",
              " \n",
              "        [[110, 101,  98],\n",
              "         [113, 104, 101],\n",
              "         [114, 105, 102],\n",
              "         ...,\n",
              "         [111, 106, 107],\n",
              "         [109, 107, 107],\n",
              "         [108, 106, 106]],\n",
              " \n",
              "        [[108,  99,  96],\n",
              "         [112, 103, 100],\n",
              "         [115, 106, 103],\n",
              "         ...,\n",
              "         [111, 106, 107],\n",
              "         [108, 106, 106],\n",
              "         [108, 106, 106]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone224_jpg.rf.acb3d4a254d1049f51f2d37efc04e5c3.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.5784969329833984, 'inference': 17.632007598876953, 'postprocess': 1.4448165893554688},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[178, 179, 183],\n",
              "         [145, 146, 150],\n",
              "         [111, 112, 116],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[124, 125, 129],\n",
              "         [141, 142, 146],\n",
              "         [148, 149, 153],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[134, 135, 139],\n",
              "         [166, 167, 171],\n",
              "         [161, 162, 166],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 97, 110,  96],\n",
              "         [ 92, 105,  91],\n",
              "         [ 72,  85,  71]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 94, 104,  91],\n",
              "         [ 88,  98,  85],\n",
              "         [ 74,  84,  71]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 84,  94,  81],\n",
              "         [ 71,  81,  68],\n",
              "         [ 64,  74,  61]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone228_jpg.rf.714a3051c2badb7fb8b52f1308052bb0.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9614696502685547, 'inference': 17.390012741088867, 'postprocess': 1.4231204986572266},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [159, 213, 246],\n",
              "         [161, 215, 248],\n",
              "         [163, 217, 250]],\n",
              " \n",
              "        [[253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [162, 216, 249],\n",
              "         [163, 217, 252],\n",
              "         [165, 219, 252]],\n",
              " \n",
              "        [[253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [158, 212, 247],\n",
              "         [160, 213, 250],\n",
              "         [162, 216, 251]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 81,  79,  78],\n",
              "         [ 83,  81,  80],\n",
              "         [ 72,  70,  69],\n",
              "         ...,\n",
              "         [ 95,  86,  82],\n",
              "         [ 96,  87,  83],\n",
              "         [ 93,  84,  80]],\n",
              " \n",
              "        [[ 73,  71,  70],\n",
              "         [ 83,  81,  80],\n",
              "         [ 70,  68,  67],\n",
              "         ...,\n",
              "         [ 95,  86,  82],\n",
              "         [ 94,  85,  81],\n",
              "         [ 89,  80,  76]],\n",
              " \n",
              "        [[ 71,  69,  68],\n",
              "         [ 97,  95,  94],\n",
              "         [ 93,  91,  90],\n",
              "         ...,\n",
              "         [ 94,  85,  81],\n",
              "         [ 91,  82,  78],\n",
              "         [ 84,  75,  71]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone254_jpg.rf.2c00cbd7f8d7d40989125e756772743d.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.1202564239501953, 'inference': 17.480134963989258, 'postprocess': 1.9223690032958984},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[165, 217, 255],\n",
              "         [163, 215, 255],\n",
              "         [161, 213, 254],\n",
              "         ...,\n",
              "         [251, 255, 255],\n",
              "         [ 86,  91,  90],\n",
              "         [  0,   4,   3]],\n",
              " \n",
              "        [[164, 216, 255],\n",
              "         [162, 214, 255],\n",
              "         [161, 213, 254],\n",
              "         ...,\n",
              "         [251, 255, 255],\n",
              "         [ 86,  91,  90],\n",
              "         [  0,   3,   2]],\n",
              " \n",
              "        [[163, 215, 255],\n",
              "         [161, 213, 254],\n",
              "         [159, 211, 252],\n",
              "         ...,\n",
              "         [251, 255, 255],\n",
              "         [ 84,  89,  88],\n",
              "         [  0,   3,   2]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 91,  89,  88],\n",
              "         [ 85,  83,  82],\n",
              "         [ 75,  73,  72],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 24,  24,  24],\n",
              "         [ 18,  18,  18],\n",
              "         [ 10,  10,  10],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  6,   6,   6],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone254_jpg.rf.30c6695652678dc30744ef32e246bab5.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0301342010498047, 'inference': 17.773866653442383, 'postprocess': 1.3625621795654297},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[208, 195, 173],\n",
              "         [164, 151, 129],\n",
              "         [ 99,  88,  68],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[213, 200, 178],\n",
              "         [215, 202, 180],\n",
              "         [218, 204, 185],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[207, 193, 171],\n",
              "         [204, 191, 169],\n",
              "         [203, 189, 170],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 51,  45,  34],\n",
              "         [ 51,  45,  34],\n",
              "         [ 50,  44,  33],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   1,   1]],\n",
              " \n",
              "        [[ 52,  46,  35],\n",
              "         [ 51,  45,  34],\n",
              "         [ 50,  44,  33],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   1,   1]],\n",
              " \n",
              "        [[ 52,  46,  35],\n",
              "         [ 52,  46,  35],\n",
              "         [ 51,  45,  34],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   1,   1]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone25_jpg.rf.b1460a7aa7c1cd514a7af0b041677ff8.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.2356510162353516, 'inference': 17.777204513549805, 'postprocess': 1.3537406921386719},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[250, 250, 250],\n",
              "         [255, 255, 255],\n",
              "         [248, 248, 248],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[221, 221, 221],\n",
              "         [255, 255, 255],\n",
              "         [250, 250, 250],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[176, 176, 176],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone27_jpg.rf.3877d055b0cc6c00e264e9c8f7863426.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9998550415039062, 'inference': 17.597675323486328, 'postprocess': 1.3785362243652344},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone290_jpg.rf.8cf515f47740d9e57a62556f65099d9c.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.153158187866211, 'inference': 17.593860626220703, 'postprocess': 1.4607906341552734},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[251, 251, 251],\n",
              "         [212, 212, 212],\n",
              "         [150, 150, 150],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [252, 252, 252],\n",
              "         [252, 252, 252],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[244, 244, 244],\n",
              "         [247, 247, 247],\n",
              "         [252, 252, 252],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 34,  19,  33],\n",
              "         [ 34,  19,  33],\n",
              "         [ 35,  20,  34],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 36,  22,  34],\n",
              "         [ 37,  23,  35],\n",
              "         [ 37,  23,  35],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 39,  25,  37],\n",
              "         [ 39,  25,  37],\n",
              "         [ 39,  25,  37],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone296_jpg.rf.373420a8d5681cdbd476657c407bb98c.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.1419525146484375, 'inference': 17.65155792236328, 'postprocess': 1.4338493347167969},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [254, 255, 251],\n",
              "         [254, 255, 251],\n",
              "         [254, 255, 251]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [254, 255, 251],\n",
              "         [254, 255, 251],\n",
              "         [254, 255, 250]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [253, 254, 250],\n",
              "         [253, 255, 249],\n",
              "         [253, 255, 249]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone298_jpg.rf.5c1e80f7d0545c38c88875f1c26559c2.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0570755004882812, 'inference': 17.573833465576172, 'postprocess': 1.2958049774169922},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone30_jpg.rf.e355b529cb6234e41ca42442eca44a37.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0928382873535156, 'inference': 17.505407333374023, 'postprocess': 1.5172958374023438},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [251, 251, 251],\n",
              "         [247, 247, 247],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [251, 251, 251],\n",
              "         [252, 252, 252],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[252, 252, 252],\n",
              "         [205, 205, 205],\n",
              "         [136, 136, 136],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone33_jpg.rf.6d28586b94e369fef04ce544615c637c.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9938945770263672, 'inference': 17.377376556396484, 'postprocess': 1.3074874877929688},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 91,  74,  53],\n",
              "         [118, 104,  82],\n",
              "         [128, 112,  95],\n",
              "         ...,\n",
              "         [162, 151, 124],\n",
              "         [234, 217, 191],\n",
              "         [225, 206, 179]],\n",
              " \n",
              "        [[ 99,  80,  59],\n",
              "         [ 98,  79,  58],\n",
              "         [ 82,  65,  46],\n",
              "         ...,\n",
              "         [202, 195, 170],\n",
              "         [232, 221, 194],\n",
              "         [221, 209, 181]],\n",
              " \n",
              "        [[153, 129, 107],\n",
              "         [113,  90,  68],\n",
              "         [ 84,  63,  42],\n",
              "         ...,\n",
              "         [214, 217, 192],\n",
              "         [158, 159, 133],\n",
              "         [204, 203, 175]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[129, 120, 117],\n",
              "         [128, 119, 116],\n",
              "         [122, 113, 110],\n",
              "         ...,\n",
              "         [142, 148, 153],\n",
              "         [151, 156, 159],\n",
              "         [158, 162, 163]],\n",
              " \n",
              "        [[134, 125, 122],\n",
              "         [133, 124, 121],\n",
              "         [139, 130, 127],\n",
              "         ...,\n",
              "         [162, 167, 170],\n",
              "         [146, 148, 148],\n",
              "         [106, 108, 108]],\n",
              " \n",
              "        [[122, 113, 110],\n",
              "         [139, 130, 127],\n",
              "         [150, 141, 138],\n",
              "         ...,\n",
              "         [161, 165, 166],\n",
              "         [154, 156, 156],\n",
              "         [119, 120, 118]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone44_jpg.rf.105bb3532a94f87034e6277a1e52aa7b.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9922256469726562, 'inference': 17.8072452545166, 'postprocess': 1.2977123260498047},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[136, 156, 181],\n",
              "         [135, 155, 180],\n",
              "         [135, 155, 180],\n",
              "         ...,\n",
              "         [100, 134, 157],\n",
              "         [ 80, 114, 137],\n",
              "         [ 25,  59,  82]],\n",
              " \n",
              "        [[148, 168, 193],\n",
              "         [148, 169, 191],\n",
              "         [148, 168, 193],\n",
              "         ...,\n",
              "         [104, 138, 161],\n",
              "         [105, 139, 162],\n",
              "         [ 77, 111, 134]],\n",
              " \n",
              "        [[162, 183, 205],\n",
              "         [162, 183, 204],\n",
              "         [162, 183, 205],\n",
              "         ...,\n",
              "         [ 91, 125, 148],\n",
              "         [105, 139, 162],\n",
              "         [101, 135, 158]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[147, 152, 161],\n",
              "         [151, 156, 165],\n",
              "         [155, 160, 169],\n",
              "         ...,\n",
              "         [152, 149, 151],\n",
              "         [152, 149, 151],\n",
              "         [153, 150, 152]],\n",
              " \n",
              "        [[150, 155, 164],\n",
              "         [156, 161, 170],\n",
              "         [161, 166, 175],\n",
              "         ...,\n",
              "         [155, 152, 154],\n",
              "         [156, 151, 153],\n",
              "         [156, 151, 153]],\n",
              " \n",
              "        [[151, 156, 165],\n",
              "         [158, 163, 172],\n",
              "         [164, 169, 178],\n",
              "         ...,\n",
              "         [159, 156, 158],\n",
              "         [159, 154, 156],\n",
              "         [158, 153, 155]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone49_jpg.rf.5a7a18e1ec272fddf6cc408db83f0ec6.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.2706985473632812, 'inference': 17.906904220581055, 'postprocess': 1.3222694396972656},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[248, 246, 245],\n",
              "         [201, 199, 198],\n",
              "         [132, 130, 129],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[250, 248, 247],\n",
              "         [245, 243, 242],\n",
              "         [244, 242, 241],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 254],\n",
              "         [255, 253, 252],\n",
              "         [251, 249, 248],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone59_jpg.rf.1ec6eafc00a268782d37af35e135ac83.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0105838775634766, 'inference': 17.64535903930664, 'postprocess': 1.3082027435302734},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[147, 151, 145],\n",
              "         [132, 136, 130],\n",
              "         [109, 113, 107],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[152, 156, 150],\n",
              "         [146, 150, 144],\n",
              "         [138, 142, 136],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[157, 161, 155],\n",
              "         [157, 161, 155],\n",
              "         [153, 157, 151],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 41,  46,  37],\n",
              "         [ 11,  16,   7],\n",
              "         [ 13,  19,   8],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  7,  12,   3],\n",
              "         [ 20,  25,  16],\n",
              "         [ 26,  32,  21],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 24,  29,  20],\n",
              "         [ 19,  24,  15],\n",
              "         [  9,  15,   4],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone61_jpg.rf.510cc8528b91e70cf9fa96ad784e14fa.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.061605453491211, 'inference': 17.490625381469727, 'postprocess': 1.2936592102050781},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[206, 206, 222],\n",
              "         [157, 157, 173],\n",
              "         [161, 161, 177],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[227, 227, 243],\n",
              "         [220, 220, 236],\n",
              "         [216, 216, 232],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[216, 216, 232],\n",
              "         [217, 217, 233],\n",
              "         [212, 212, 228],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[149, 166, 169],\n",
              "         [147, 164, 167],\n",
              "         [142, 160, 161],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[155, 172, 175],\n",
              "         [163, 180, 183],\n",
              "         [164, 182, 183],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[141, 158, 161],\n",
              "         [151, 168, 171],\n",
              "         [131, 149, 150],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone61_jpg.rf.f4cf37c93f915f63853d3a6939b8f5e3.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.995086669921875, 'inference': 17.164945602416992, 'postprocess': 1.3654232025146484},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [244, 244, 244],\n",
              "         [223, 223, 223],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         [250, 250, 250],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[253, 253, 253],\n",
              "         [250, 250, 250],\n",
              "         [249, 249, 249],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[239, 241, 249],\n",
              "         [229, 232, 253],\n",
              "         [215, 216, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[242, 248, 225],\n",
              "         [238, 243, 234],\n",
              "         [233, 238, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 225],\n",
              "         [244, 252, 229],\n",
              "         [237, 243, 250],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone65_jpg.rf.4c42a0fb577fec3a7e7664aff351b498.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.151966094970703, 'inference': 17.027854919433594, 'postprocess': 2.0520687103271484},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[124, 117, 120],\n",
              "         [120, 113, 116],\n",
              "         [ 99,  94,  96],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   1,   0],\n",
              "         [  1,   2,   0]],\n",
              " \n",
              "        [[118, 111, 114],\n",
              "         [151, 144, 147],\n",
              "         [114, 109, 111],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   1,   0],\n",
              "         [  1,   2,   0]],\n",
              " \n",
              "        [[151, 146, 148],\n",
              "         [168, 163, 165],\n",
              "         [129, 124, 126],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   1,   0],\n",
              "         [  1,   2,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  2,   2,   2],\n",
              "         [  2,   2,   2],\n",
              "         [  2,   2,   2],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  2,   2,   2],\n",
              "         [  2,   2,   2],\n",
              "         [  2,   2,   2],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  2,   2,   2],\n",
              "         [  2,   2,   2],\n",
              "         [  2,   2,   2],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone6_jpg.rf.19b1ef240eaa7c7d461a53a73ac48460.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.011537551879883, 'inference': 17.031431198120117, 'postprocess': 1.5234947204589844},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[127, 127, 133],\n",
              "         [137, 137, 143],\n",
              "         [145, 145, 151],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[164, 164, 170],\n",
              "         [185, 185, 191],\n",
              "         [210, 210, 216],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[166, 165, 174],\n",
              "         [178, 177, 186],\n",
              "         [191, 190, 199],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[157, 157, 169],\n",
              "         [154, 154, 166],\n",
              "         [148, 148, 160],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[147, 149, 160],\n",
              "         [149, 151, 162],\n",
              "         [152, 154, 165],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[159, 161, 172],\n",
              "         [158, 160, 171],\n",
              "         [161, 163, 174],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone6_jpg.rf.5128fa27230510804a9f923d347c4035.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.2745132446289062, 'inference': 17.34614372253418, 'postprocess': 1.3873577117919922},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[121, 141, 142],\n",
              "         [140, 160, 161],\n",
              "         [ 95, 116, 114],\n",
              "         ...,\n",
              "         [  6,  13,  10],\n",
              "         [  8,  13,   4],\n",
              "         [  8,  14,   3]],\n",
              " \n",
              "        [[140, 158, 159],\n",
              "         [180, 200, 201],\n",
              "         [147, 165, 164],\n",
              "         ...,\n",
              "         [  5,  12,   9],\n",
              "         [  7,  12,   3],\n",
              "         [  8,  14,   3]],\n",
              " \n",
              "        [[150, 166, 165],\n",
              "         [163, 181, 180],\n",
              "         [176, 192, 191],\n",
              "         ...,\n",
              "         [  4,  11,   8],\n",
              "         [  6,  11,   2],\n",
              "         [  7,  13,   2]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[122, 151, 155],\n",
              "         [ 97, 126, 130],\n",
              "         [ 72,  99, 103],\n",
              "         ...,\n",
              "         [ 23,  31,  31],\n",
              "         [ 61,  69,  69],\n",
              "         [123, 131, 131]],\n",
              " \n",
              "        [[ 88, 116, 117],\n",
              "         [ 44,  72,  73],\n",
              "         [ 86, 111, 113],\n",
              "         ...,\n",
              "         [ 60,  66,  65],\n",
              "         [ 68,  74,  73],\n",
              "         [ 80,  86,  85]],\n",
              " \n",
              "        [[ 74, 102, 103],\n",
              "         [ 68,  96,  97],\n",
              "         [131, 156, 158],\n",
              "         ...,\n",
              "         [ 26,  32,  31],\n",
              "         [ 27,  33,  32],\n",
              "         [ 45,  51,  50]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone73_jpg.rf.4d271a58475e016d5df30e3d4757314b.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0570755004882812, 'inference': 17.857074737548828, 'postprocess': 1.3985633850097656},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[  9,   8,  10],\n",
              "         [  7,   9,  10],\n",
              "         [  2,   7,   6],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 11,  10,  12],\n",
              "         [ 10,  12,  13],\n",
              "         [  7,  12,  11],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[ 10,  10,  10],\n",
              "         [ 11,  13,  13],\n",
              "         [  9,  14,  13],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [110, 107, 103],\n",
              "         [126, 123, 119],\n",
              "         [111, 108, 104]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [133, 132, 128],\n",
              "         [155, 154, 150],\n",
              "         [143, 142, 138]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [126, 125, 121],\n",
              "         [120, 119, 115],\n",
              "         [138, 137, 133]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone73_jpg.rf.ffcbe395de91dee3f41e1d1a8715e0e9.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.031564712524414, 'inference': 17.811059951782227, 'postprocess': 1.3737678527832031},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[  0,  23, 157],\n",
              "         [  0,  15, 163],\n",
              "         [  0,  10, 188],\n",
              "         ...,\n",
              "         [  0,  16, 189],\n",
              "         [  0,  15, 175],\n",
              "         [  0,  19, 172]],\n",
              " \n",
              "        [[  0,  21, 171],\n",
              "         [  0,  11, 174],\n",
              "         [  0,   2, 191],\n",
              "         ...,\n",
              "         [  0,   1, 184],\n",
              "         [  0,  15, 186],\n",
              "         [  0,  17, 183]],\n",
              " \n",
              "        [[  0,   0, 176],\n",
              "         [  0,   4, 193],\n",
              "         [ 13,   1, 213],\n",
              "         ...,\n",
              "         [  4,   0, 201],\n",
              "         [  6,  10, 205],\n",
              "         [  0,   0, 185]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   4, 185],\n",
              "         [  7,  11, 200],\n",
              "         [ 18,   6, 218],\n",
              "         ...,\n",
              "         [ 20,  12, 197],\n",
              "         [  4,   5, 187],\n",
              "         [  4,   8, 190]],\n",
              " \n",
              "        [[  0,  15, 167],\n",
              "         [  0,   5, 168],\n",
              "         [  0,   0, 184],\n",
              "         ...,\n",
              "         [  0,   0, 177],\n",
              "         [  0,   0, 172],\n",
              "         [  0,  11, 181]],\n",
              " \n",
              "        [[  0,  26, 163],\n",
              "         [  0,  18, 168],\n",
              "         [  2,  12, 189],\n",
              "         ...,\n",
              "         [  4,  11, 184],\n",
              "         [  0,   8, 176],\n",
              "         [  0,   8, 171]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone75_jpg.rf.8b8d785c0f5d716bfdb340d1bb57d321.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.000093460083008, 'inference': 17.51995086669922, 'postprocess': 1.3456344604492188},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[159, 112,  21],\n",
              "         [155, 108,  17],\n",
              "         [146,  99,  13],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[167, 118,  26],\n",
              "         [167, 118,  26],\n",
              "         [166, 116,  26],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[165, 112,  15],\n",
              "         [166, 113,  16],\n",
              "         [167, 113,  18],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[232, 188, 141],\n",
              "         [232, 188, 141],\n",
              "         [232, 188, 141],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[232, 188, 141],\n",
              "         [232, 188, 141],\n",
              "         [232, 188, 141],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[232, 188, 141],\n",
              "         [232, 188, 141],\n",
              "         [232, 188, 141],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone76_jpg.rf.4e7699b2df05cef85c9e2acbf79bd7a0.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9876956939697266, 'inference': 17.288923263549805, 'postprocess': 1.4073848724365234},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[228, 191, 163],\n",
              "         [228, 191, 163],\n",
              "         [228, 191, 163],\n",
              "         ...,\n",
              "         [228, 192, 162],\n",
              "         [228, 192, 162],\n",
              "         [228, 192, 162]],\n",
              " \n",
              "        [[228, 191, 163],\n",
              "         [228, 191, 163],\n",
              "         [228, 191, 163],\n",
              "         ...,\n",
              "         [228, 192, 162],\n",
              "         [228, 192, 162],\n",
              "         [228, 192, 162]],\n",
              " \n",
              "        [[228, 191, 163],\n",
              "         [228, 191, 163],\n",
              "         [228, 191, 163],\n",
              "         ...,\n",
              "         [228, 192, 162],\n",
              "         [228, 192, 162],\n",
              "         [228, 192, 162]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[141, 146, 149],\n",
              "         [139, 144, 147],\n",
              "         [135, 138, 142],\n",
              "         ...,\n",
              "         [112, 108, 119],\n",
              "         [107, 103, 114],\n",
              "         [105, 101, 112]],\n",
              " \n",
              "        [[145, 150, 153],\n",
              "         [142, 147, 150],\n",
              "         [140, 143, 147],\n",
              "         ...,\n",
              "         [112, 108, 119],\n",
              "         [110, 106, 117],\n",
              "         [109, 105, 116]],\n",
              " \n",
              "        [[135, 140, 143],\n",
              "         [135, 140, 143],\n",
              "         [138, 141, 145],\n",
              "         ...,\n",
              "         [111, 107, 118],\n",
              "         [114, 110, 121],\n",
              "         [117, 113, 124]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone81_jpg.rf.8ed1c26363640e44d1ef7d63943bc32a.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.00653076171875, 'inference': 17.014026641845703, 'postprocess': 1.3117790222167969},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone86_jpg.rf.a88f62753b61ea5aa7c09bb3d0d936aa.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.132892608642578, 'inference': 18.01776885986328, 'postprocess': 2.1827220916748047},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[116, 107,  93],\n",
              "         [111, 102,  88],\n",
              "         [104,  95,  81],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[112, 103,  89],\n",
              "         [111, 102,  88],\n",
              "         [110, 101,  87],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[113, 104,  90],\n",
              "         [115, 106,  92],\n",
              "         [116, 107,  93],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 90,  91,  75],\n",
              "         [ 89,  90,  74],\n",
              "         [ 90,  91,  75]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 94,  95,  79],\n",
              "         [ 91,  92,  76],\n",
              "         [ 90,  91,  75]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [ 93,  94,  78],\n",
              "         [ 88,  89,  73],\n",
              "         [ 87,  88,  72]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone8_jpg.rf.815f646edf5a612687cf5568ab974743.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0384788513183594, 'inference': 17.020463943481445, 'postprocess': 2.4428367614746094},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[201, 140,  36],\n",
              "         [201, 140,  36],\n",
              "         [202, 141,  37],\n",
              "         ...,\n",
              "         [178, 122,   0],\n",
              "         [178, 122,   0],\n",
              "         [178, 122,   0]],\n",
              " \n",
              "        [[201, 140,  36],\n",
              "         [201, 140,  36],\n",
              "         [202, 141,  37],\n",
              "         ...,\n",
              "         [178, 122,   0],\n",
              "         [178, 122,   0],\n",
              "         [178, 122,   0]],\n",
              " \n",
              "        [[203, 141,  35],\n",
              "         [203, 141,  35],\n",
              "         [201, 140,  36],\n",
              "         ...,\n",
              "         [178, 122,   0],\n",
              "         [178, 122,   0],\n",
              "         [178, 122,   0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[128, 129, 127],\n",
              "         [112, 113, 111],\n",
              "         [116, 117, 115],\n",
              "         ...,\n",
              "         [ 79,  47,  11],\n",
              "         [ 67,  35,   0],\n",
              "         [ 62,  30,   0]],\n",
              " \n",
              "        [[111, 112, 110],\n",
              "         [ 96,  97,  95],\n",
              "         [106, 107, 105],\n",
              "         ...,\n",
              "         [ 75,  46,   7],\n",
              "         [ 66,  37,   0],\n",
              "         [ 65,  36,   0]],\n",
              " \n",
              "        [[137, 138, 136],\n",
              "         [ 86,  87,  85],\n",
              "         [ 91,  92,  90],\n",
              "         ...,\n",
              "         [ 71,  43,   2],\n",
              "         [ 63,  35,   0],\n",
              "         [ 66,  38,   0]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/road-traffic-cone95_jpg.rf.6a2c46328a2de919ed096af3d532014c.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0012855529785156, 'inference': 17.577171325683594, 'postprocess': 1.4052391052246094},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[246, 226, 221],\n",
              "         [244, 224, 219],\n",
              "         [242, 222, 217],\n",
              "         ...,\n",
              "         [118, 122, 117],\n",
              "         [118, 122, 117],\n",
              "         [111, 115, 110]],\n",
              " \n",
              "        [[245, 225, 220],\n",
              "         [244, 224, 219],\n",
              "         [241, 221, 216],\n",
              "         ...,\n",
              "         [111, 115, 110],\n",
              "         [113, 117, 112],\n",
              "         [108, 112, 107]],\n",
              " \n",
              "        [[245, 225, 220],\n",
              "         [243, 223, 218],\n",
              "         [240, 220, 215],\n",
              "         ...,\n",
              "         [100, 104,  99],\n",
              "         [107, 111, 106],\n",
              "         [107, 111, 106]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[171, 196, 212],\n",
              "         [166, 191, 207],\n",
              "         [161, 186, 202],\n",
              "         ...,\n",
              "         [ 37,  43,  42],\n",
              "         [ 34,  40,  39],\n",
              "         [ 31,  37,  36]],\n",
              " \n",
              "        [[170, 195, 211],\n",
              "         [166, 191, 207],\n",
              "         [160, 185, 201],\n",
              "         ...,\n",
              "         [ 38,  44,  43],\n",
              "         [ 34,  40,  39],\n",
              "         [ 32,  38,  37]],\n",
              " \n",
              "        [[170, 195, 211],\n",
              "         [165, 190, 206],\n",
              "         [160, 185, 201],\n",
              "         ...,\n",
              "         [ 38,  44,  43],\n",
              "         [ 34,  40,  39],\n",
              "         [ 32,  38,  37]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-1811886949-2098761804-fm-253-fmt-auto-app-138-f-JPEG_webp_jpg.rf.e2d03bb5e29af41e11738d29f550cba1.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.1703243255615234, 'inference': 17.83156394958496, 'postprocess': 1.3191699981689453},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[243, 241, 241],\n",
              "         [243, 241, 241],\n",
              "         [243, 241, 241],\n",
              "         ...,\n",
              "         [ 31,  34,  25],\n",
              "         [ 29,  32,  23],\n",
              "         [ 26,  29,  20]],\n",
              " \n",
              "        [[243, 241, 241],\n",
              "         [243, 241, 241],\n",
              "         [243, 241, 241],\n",
              "         ...,\n",
              "         [ 30,  33,  24],\n",
              "         [ 27,  30,  21],\n",
              "         [ 25,  28,  19]],\n",
              " \n",
              "        [[243, 241, 241],\n",
              "         [243, 241, 241],\n",
              "         [243, 241, 241],\n",
              "         ...,\n",
              "         [ 29,  32,  23],\n",
              "         [ 26,  29,  20],\n",
              "         [ 23,  26,  17]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[163, 174, 182],\n",
              "         [170, 181, 189],\n",
              "         [171, 182, 190],\n",
              "         ...,\n",
              "         [ 65,  86, 114],\n",
              "         [ 58,  78, 109],\n",
              "         [ 56,  76, 107]],\n",
              " \n",
              "        [[163, 174, 182],\n",
              "         [170, 181, 189],\n",
              "         [172, 183, 191],\n",
              "         ...,\n",
              "         [ 63,  84, 112],\n",
              "         [ 56,  76, 107],\n",
              "         [ 58,  78, 109]],\n",
              " \n",
              "        [[163, 174, 182],\n",
              "         [171, 182, 190],\n",
              "         [173, 184, 192],\n",
              "         ...,\n",
              "         [ 62,  83, 111],\n",
              "         [ 55,  75, 106],\n",
              "         [ 60,  80, 111]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-2039279726-4285130551-fm-253-fmt-auto-app-120-f-JPEG_webp_jpg.rf.261d21a4dee6a13947455a1b2296c629.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.020597457885742, 'inference': 17.7919864654541, 'postprocess': 1.3818740844726562},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[ 37,  18,  15],\n",
              "         [ 37,  18,  15],\n",
              "         [ 37,  18,  15],\n",
              "         ...,\n",
              "         [ 32,  14,  27],\n",
              "         [ 32,  14,  27],\n",
              "         [ 32,  14,  27]],\n",
              " \n",
              "        [[ 37,  18,  15],\n",
              "         [ 37,  18,  15],\n",
              "         [ 38,  19,  16],\n",
              "         ...,\n",
              "         [ 32,  14,  27],\n",
              "         [ 32,  14,  27],\n",
              "         [ 32,  14,  27]],\n",
              " \n",
              "        [[ 38,  19,  16],\n",
              "         [ 38,  19,  16],\n",
              "         [ 39,  20,  17],\n",
              "         ...,\n",
              "         [ 32,  14,  27],\n",
              "         [ 32,  14,  27],\n",
              "         [ 32,  14,  27]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[167, 139,  85],\n",
              "         [165, 137,  83],\n",
              "         [163, 137,  83],\n",
              "         ...,\n",
              "         [ 10,   5,   2],\n",
              "         [ 10,   5,   2],\n",
              "         [ 10,   5,   2]],\n",
              " \n",
              "        [[172, 143,  92],\n",
              "         [163, 134,  83],\n",
              "         [156, 129,  78],\n",
              "         ...,\n",
              "         [ 10,   5,   2],\n",
              "         [ 10,   5,   2],\n",
              "         [ 10,   5,   2]],\n",
              " \n",
              "        [[177, 148,  97],\n",
              "         [161, 132,  81],\n",
              "         [150, 123,  73],\n",
              "         ...,\n",
              "         [ 10,   5,   2],\n",
              "         [ 10,   5,   2],\n",
              "         [ 10,   5,   2]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-2327145301-2862418166-fm-253-fmt-auto-app-138-f-JPEG_webp_jpg.rf.3aed9477c6a5ad8ae420a3748d14986e.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 1.9948482513427734, 'inference': 17.659425735473633, 'postprocess': 1.3821125030517578},\n",
              " ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'guard rail', 1: 'road traffic cones', 2: 'street lamp', 3: 'traffic sign'}\n",
              " obb: None\n",
              " orig_img: array([[[255, 226, 219],\n",
              "         [255, 226, 219],\n",
              "         [255, 226, 219],\n",
              "         ...,\n",
              "         [247, 221, 204],\n",
              "         [249, 223, 206],\n",
              "         [250, 224, 207]],\n",
              " \n",
              "        [[255, 226, 219],\n",
              "         [255, 226, 219],\n",
              "         [255, 226, 219],\n",
              "         ...,\n",
              "         [247, 221, 204],\n",
              "         [248, 222, 205],\n",
              "         [249, 223, 206]],\n",
              " \n",
              "        [[255, 226, 219],\n",
              "         [255, 226, 219],\n",
              "         [255, 226, 219],\n",
              "         ...,\n",
              "         [246, 220, 203],\n",
              "         [246, 220, 203],\n",
              "         [247, 221, 204]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[145,  81,  27],\n",
              "         [145,  81,  27],\n",
              "         [145,  81,  27],\n",
              "         ...,\n",
              "         [134,  82,  41],\n",
              "         [136,  86,  44],\n",
              "         [117,  69,  27]],\n",
              " \n",
              "        [[167, 108,  59],\n",
              "         [167, 108,  59],\n",
              "         [167, 108,  59],\n",
              "         ...,\n",
              "         [163, 113,  77],\n",
              "         [158, 110,  74],\n",
              "         [130,  85,  48]],\n",
              " \n",
              "        [[205, 146, 100],\n",
              "         [205, 146, 100],\n",
              "         [205, 146, 100],\n",
              "         ...,\n",
              "         [206, 160, 126],\n",
              "         [196, 150, 116],\n",
              "         [162, 117,  83]]], dtype=uint8)\n",
              " orig_shape: (640, 640)\n",
              " path: '/content/drive/MyDrive/sony/latest.v1i.yolov8/test/images/u-3499193694-1018368932-fm-253-fmt-auto-app-120-f-JPEG_webp_jpg.rf.5fd7308f6fc11b53042b0dd066f25fc1.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict2'\n",
              " speed: {'preprocess': 2.0787715911865234, 'inference': 17.408132553100586, 'postprocess': 1.4617443084716797}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Image(filename=\"runs\\\\detect\\\\predict\\\\u-1811886949-2098761804-fm-253-fmt-auto-app-138-f-JPEG_webp_jpg.rf.e2d03bb5e29af41e11738d29f550cba1.jpg\", width=600)"
      ],
      "metadata": {
        "id": "2Tl0XZDthX49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Define video paths and dimensions\n",
        "VIDEO_DIR = \"/content/drive/MyDrive/sony\"\n",
        "VIDEO_NAME = \"video.mp4\"\n",
        "VIDEO_PATH = os.path.join(VIDEO_DIR, VIDEO_NAME)\n",
        "VIDEO_OUT_PATH = '/content/drive/MyDrive/sony/resultvideo.mp4'\n",
        "H, W = 1020, 1920  # Video frame dimensions\n",
        "\n",
        "# Initialize video capture and video writer objects\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "out = cv2.VideoWriter(VIDEO_OUT_PATH, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n",
        "\n",
        "# Load YOLO model\n",
        "model_path = \"/content/runs/detect/train/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Set detection threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Process each frame of the video\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(frame)[0]\n",
        "\n",
        "    # Annotate detected objects\n",
        "    for result in results.boxes.data.tolist():\n",
        "        x1, y1, x2, y2, score, class_id = result\n",
        "        if score > threshold:\n",
        "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
        "            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
        "\n",
        "    # Write annotated frame to output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl7HNv5D4BOF",
        "outputId": "99cdbeb5-7329-4af4-eacd-5acb966d0e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 352x640 (no detections), 132.4ms\n",
            "Speed: 2.5ms preprocess, 132.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 25.2ms\n",
            "Speed: 3.3ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 25.2ms\n",
            "Speed: 3.4ms preprocess, 25.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 25.1ms\n",
            "Speed: 3.2ms preprocess, 25.1ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 25.2ms\n",
            "Speed: 3.1ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.9ms\n",
            "Speed: 2.9ms preprocess, 20.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.6ms\n",
            "Speed: 3.7ms preprocess, 20.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.6ms\n",
            "Speed: 3.6ms preprocess, 20.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.7ms\n",
            "Speed: 3.2ms preprocess, 20.7ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.6ms\n",
            "Speed: 3.2ms preprocess, 20.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 3.0ms preprocess, 17.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 2.9ms preprocess, 17.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 3.0ms preprocess, 17.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.1ms\n",
            "Speed: 3.5ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 2.1ms preprocess, 17.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.3ms\n",
            "Speed: 4.5ms preprocess, 17.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 3.1ms preprocess, 17.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.5ms\n",
            "Speed: 3.0ms preprocess, 17.5ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.8ms\n",
            "Speed: 3.3ms preprocess, 16.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 3.5ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.3ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.1ms\n",
            "Speed: 2.3ms preprocess, 20.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 2.9ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.3ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.0ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 3.5ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 3.5ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 3.6ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.7ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.3ms\n",
            "Speed: 2.9ms preprocess, 17.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.6ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.9ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.0ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 3.2ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 3.4ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.5ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.6ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.9ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.6ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 3.4ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 3.5ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 3.3ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.6ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.2ms\n",
            "Speed: 2.6ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 4.0ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.8ms\n",
            "Speed: 2.7ms preprocess, 17.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.9ms preprocess, 16.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.5ms\n",
            "Speed: 2.9ms preprocess, 15.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.2ms\n",
            "Speed: 2.1ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 2.6ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.5ms\n",
            "Speed: 2.8ms preprocess, 15.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.5ms\n",
            "Speed: 2.6ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 3.6ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.1ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 3.4ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 4.1ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 3.8ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 4.2ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.8ms\n",
            "Speed: 4.2ms preprocess, 18.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.0ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.6ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.9ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 4.2ms preprocess, 16.1ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 4.3ms preprocess, 15.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.5ms\n",
            "Speed: 4.0ms preprocess, 16.5ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 3.2ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 5.2ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.6ms\n",
            "Speed: 2.9ms preprocess, 16.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 21.2ms\n",
            "Speed: 2.9ms preprocess, 21.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.2ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.7ms\n",
            "Speed: 2.7ms preprocess, 16.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.5ms\n",
            "Speed: 2.9ms preprocess, 16.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.8ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 3.8ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.3ms preprocess, 15.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.8ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.6ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 5.0ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.4ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.6ms\n",
            "Speed: 2.7ms preprocess, 17.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.4ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.3ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.0ms\n",
            "Speed: 2.8ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.7ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 4.5ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 4.2ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 4.1ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 3.5ms preprocess, 17.2ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 4.1ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.6ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.7ms\n",
            "Speed: 4.2ms preprocess, 16.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 4.0ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.8ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 3.1ms preprocess, 17.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 4.0ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.6ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.6ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 4.3ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 19.9ms\n",
            "Speed: 2.9ms preprocess, 19.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.5ms\n",
            "Speed: 2.8ms preprocess, 17.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 18.3ms\n",
            "Speed: 2.8ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.6ms\n",
            "Speed: 3.0ms preprocess, 20.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 5.6ms preprocess, 16.1ms inference, 2.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 3.8ms preprocess, 16.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 23.7ms\n",
            "Speed: 3.8ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.0ms\n",
            "Speed: 3.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 21.4ms\n",
            "Speed: 2.7ms preprocess, 21.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.2ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 4.1ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 2.9ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.7ms\n",
            "Speed: 3.3ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 2.9ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.6ms\n",
            "Speed: 3.4ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.3ms\n",
            "Speed: 2.9ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.3ms\n",
            "Speed: 3.6ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.0ms\n",
            "Speed: 3.0ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.5ms\n",
            "Speed: 3.0ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.6ms\n",
            "Speed: 3.1ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.5ms\n",
            "Speed: 3.7ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.9ms\n",
            "Speed: 3.1ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.5ms\n",
            "Speed: 3.3ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.3ms\n",
            "Speed: 3.2ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 24.6ms\n",
            "Speed: 3.5ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.7ms\n",
            "Speed: 3.1ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.9ms\n",
            "Speed: 3.2ms preprocess, 18.9ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 24.6ms\n",
            "Speed: 3.2ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 26.8ms\n",
            "Speed: 3.1ms preprocess, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.4ms\n",
            "Speed: 3.0ms preprocess, 21.4ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.2ms\n",
            "Speed: 3.1ms preprocess, 18.2ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.4ms\n",
            "Speed: 5.9ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.3ms\n",
            "Speed: 2.9ms preprocess, 20.3ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.1ms\n",
            "Speed: 2.9ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.4ms\n",
            "Speed: 3.1ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.6ms\n",
            "Speed: 2.8ms preprocess, 22.6ms inference, 6.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.8ms\n",
            "Speed: 3.0ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.0ms\n",
            "Speed: 3.0ms preprocess, 20.0ms inference, 4.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.8ms\n",
            "Speed: 2.8ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.7ms\n",
            "Speed: 2.8ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.7ms\n",
            "Speed: 3.1ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.7ms\n",
            "Speed: 2.6ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.1ms\n",
            "Speed: 2.8ms preprocess, 19.1ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.0ms\n",
            "Speed: 2.7ms preprocess, 19.0ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.1ms\n",
            "Speed: 2.7ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.0ms\n",
            "Speed: 2.6ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.1ms\n",
            "Speed: 2.7ms preprocess, 19.1ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.0ms\n",
            "Speed: 2.7ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.1ms\n",
            "Speed: 4.6ms preprocess, 19.1ms inference, 3.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.4ms\n",
            "Speed: 2.7ms preprocess, 21.4ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.3ms\n",
            "Speed: 3.3ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.2ms\n",
            "Speed: 2.9ms preprocess, 21.2ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.5ms\n",
            "Speed: 3.3ms preprocess, 20.5ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.4ms\n",
            "Speed: 2.8ms preprocess, 19.4ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.3ms\n",
            "Speed: 2.9ms preprocess, 20.3ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 25.1ms\n",
            "Speed: 2.8ms preprocess, 25.1ms inference, 2.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.9ms\n",
            "Speed: 6.3ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.2ms\n",
            "Speed: 4.5ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.4ms\n",
            "Speed: 3.5ms preprocess, 22.4ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 25.1ms\n",
            "Speed: 5.3ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 26.0ms\n",
            "Speed: 4.4ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.5ms\n",
            "Speed: 2.9ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.8ms\n",
            "Speed: 3.3ms preprocess, 22.8ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.4ms\n",
            "Speed: 3.8ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.1ms\n",
            "Speed: 3.8ms preprocess, 20.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.0ms\n",
            "Speed: 3.8ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.9ms\n",
            "Speed: 2.6ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.1ms\n",
            "Speed: 2.8ms preprocess, 20.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.3ms\n",
            "Speed: 2.7ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.2ms\n",
            "Speed: 2.8ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.7ms\n",
            "Speed: 3.1ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.8ms\n",
            "Speed: 3.2ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 18.9ms\n",
            "Speed: 3.5ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.5ms\n",
            "Speed: 3.8ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.2ms\n",
            "Speed: 3.3ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.5ms\n",
            "Speed: 3.3ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 21.4ms\n",
            "Speed: 3.0ms preprocess, 21.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.2ms\n",
            "Speed: 2.9ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.3ms\n",
            "Speed: 3.4ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.0ms\n",
            "Speed: 3.0ms preprocess, 17.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.3ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.3ms\n",
            "Speed: 5.0ms preprocess, 17.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.5ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.9ms\n",
            "Speed: 4.2ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.2ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 21.3ms\n",
            "Speed: 3.5ms preprocess, 21.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.2ms\n",
            "Speed: 3.3ms preprocess, 17.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.6ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 4.0ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 2.6ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 22.3ms\n",
            "Speed: 3.8ms preprocess, 22.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.2ms\n",
            "Speed: 3.4ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.2ms\n",
            "Speed: 3.2ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.2ms\n",
            "Speed: 3.8ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.5ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.2ms\n",
            "Speed: 4.1ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.5ms\n",
            "Speed: 4.5ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.4ms\n",
            "Speed: 3.4ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.8ms\n",
            "Speed: 3.2ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.5ms\n",
            "Speed: 2.7ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.3ms\n",
            "Speed: 3.7ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.5ms\n",
            "Speed: 4.0ms preprocess, 15.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.8ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.3ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.4ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.8ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.5ms\n",
            "Speed: 3.9ms preprocess, 15.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.1ms\n",
            "Speed: 3.8ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.7ms\n",
            "Speed: 4.9ms preprocess, 17.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.7ms\n",
            "Speed: 3.9ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.7ms\n",
            "Speed: 3.4ms preprocess, 16.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.2ms\n",
            "Speed: 3.3ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.6ms\n",
            "Speed: 3.6ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.3ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.6ms\n",
            "Speed: 6.8ms preprocess, 16.6ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.8ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 5.1ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.6ms\n",
            "Speed: 3.0ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.3ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 3.1ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.8ms\n",
            "Speed: 3.1ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 4.7ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.8ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 18.3ms\n",
            "Speed: 2.9ms preprocess, 18.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 4.3ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.5ms\n",
            "Speed: 2.9ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.4ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 4.3ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 4.2ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.3ms\n",
            "Speed: 3.4ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 4.3ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.2ms\n",
            "Speed: 3.1ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.0ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 6.3ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 4.4ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.6ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.0ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 4.2ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.8ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.2ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.3ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 3.7ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 4.5ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.7ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 4.0ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.7ms\n",
            "Speed: 2.9ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.8ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.4ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.7ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 3.4ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 4.9ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.5ms\n",
            "Speed: 3.1ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.3ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.1ms\n",
            "Speed: 6.4ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.4ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.1ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.3ms\n",
            "Speed: 3.4ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.4ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 4.3ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.0ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 4.1ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 4.9ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.9ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.3ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.6ms\n",
            "Speed: 3.3ms preprocess, 16.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 4.2ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.6ms\n",
            "Speed: 3.0ms preprocess, 16.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.4ms\n",
            "Speed: 2.9ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 23.8ms\n",
            "Speed: 4.0ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.3ms\n",
            "Speed: 3.0ms preprocess, 19.3ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.9ms\n",
            "Speed: 5.2ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.4ms\n",
            "Speed: 2.8ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.4ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.6ms\n",
            "Speed: 6.6ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.2ms\n",
            "Speed: 3.0ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.9ms\n",
            "Speed: 3.5ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.2ms\n",
            "Speed: 3.0ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 2.9ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.9ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.8ms\n",
            "Speed: 2.9ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.0ms\n",
            "Speed: 3.7ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 4.5ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.4ms\n",
            "Speed: 2.7ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.2ms\n",
            "Speed: 2.8ms preprocess, 19.2ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.3ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 28.4ms\n",
            "Speed: 3.2ms preprocess, 28.4ms inference, 4.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.8ms\n",
            "Speed: 3.3ms preprocess, 21.8ms inference, 4.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 28.1ms\n",
            "Speed: 3.2ms preprocess, 28.1ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.4ms\n",
            "Speed: 3.0ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.1ms\n",
            "Speed: 3.1ms preprocess, 18.1ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.1ms\n",
            "Speed: 5.5ms preprocess, 22.1ms inference, 2.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 24.0ms\n",
            "Speed: 2.8ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.3ms\n",
            "Speed: 3.1ms preprocess, 19.3ms inference, 4.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.4ms\n",
            "Speed: 3.3ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.2ms\n",
            "Speed: 2.9ms preprocess, 19.2ms inference, 3.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.1ms\n",
            "Speed: 6.0ms preprocess, 19.1ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.4ms\n",
            "Speed: 2.8ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.6ms\n",
            "Speed: 3.1ms preprocess, 19.6ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.4ms\n",
            "Speed: 2.9ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.9ms\n",
            "Speed: 3.3ms preprocess, 20.9ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.3ms\n",
            "Speed: 3.2ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.3ms\n",
            "Speed: 4.7ms preprocess, 19.3ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.3ms\n",
            "Speed: 3.0ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.1ms\n",
            "Speed: 2.8ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.3ms\n",
            "Speed: 7.2ms preprocess, 20.3ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.6ms\n",
            "Speed: 2.9ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.4ms\n",
            "Speed: 2.7ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.7ms\n",
            "Speed: 2.9ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.9ms\n",
            "Speed: 3.3ms preprocess, 20.9ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.1ms\n",
            "Speed: 3.1ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.7ms\n",
            "Speed: 2.8ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 25.1ms\n",
            "Speed: 2.6ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.7ms\n",
            "Speed: 6.9ms preprocess, 19.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.5ms\n",
            "Speed: 2.9ms preprocess, 21.5ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.9ms\n",
            "Speed: 2.8ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.7ms\n",
            "Speed: 2.8ms preprocess, 22.7ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 24.9ms\n",
            "Speed: 2.9ms preprocess, 24.9ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.8ms\n",
            "Speed: 4.7ms preprocess, 21.8ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 28.5ms\n",
            "Speed: 2.9ms preprocess, 28.5ms inference, 3.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.0ms\n",
            "Speed: 2.9ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.7ms\n",
            "Speed: 4.0ms preprocess, 20.7ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.4ms\n",
            "Speed: 3.3ms preprocess, 22.4ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 23.4ms\n",
            "Speed: 6.4ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.2ms\n",
            "Speed: 5.2ms preprocess, 22.2ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.1ms\n",
            "Speed: 3.8ms preprocess, 22.1ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.0ms\n",
            "Speed: 4.0ms preprocess, 22.0ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.2ms\n",
            "Speed: 3.2ms preprocess, 22.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.3ms\n",
            "Speed: 2.9ms preprocess, 20.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.6ms\n",
            "Speed: 2.9ms preprocess, 20.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.7ms\n",
            "Speed: 2.7ms preprocess, 20.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.6ms\n",
            "Speed: 2.8ms preprocess, 20.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 22.6ms\n",
            "Speed: 2.7ms preprocess, 22.6ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.5ms\n",
            "Speed: 3.0ms preprocess, 19.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.7ms\n",
            "Speed: 2.6ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.7ms\n",
            "Speed: 2.8ms preprocess, 18.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.0ms\n",
            "Speed: 3.2ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.7ms\n",
            "Speed: 2.8ms preprocess, 20.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 2.9ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.2ms\n",
            "Speed: 4.5ms preprocess, 19.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 3.1ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 3.5ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.7ms\n",
            "Speed: 3.0ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 4.0ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.0ms\n",
            "Speed: 3.4ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.8ms\n",
            "Speed: 5.0ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.8ms\n",
            "Speed: 3.0ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 2.3ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 3.5ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 3.3ms preprocess, 17.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.9ms\n",
            "Speed: 3.3ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.6ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 3.4ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 2.9ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 4.7ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.6ms\n",
            "Speed: 2.8ms preprocess, 20.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 2.6ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.1ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 4.9ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.7ms\n",
            "Speed: 3.1ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 4.1ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 4.2ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 3.3ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 20.7ms\n",
            "Speed: 4.7ms preprocess, 20.7ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.5ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 3.4ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 21.8ms\n",
            "Speed: 3.3ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 27.5ms\n",
            "Speed: 4.2ms preprocess, 27.5ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 18.8ms\n",
            "Speed: 3.0ms preprocess, 18.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.2ms\n",
            "Speed: 3.0ms preprocess, 16.2ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.6ms\n",
            "Speed: 3.1ms preprocess, 17.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.3ms\n",
            "Speed: 3.9ms preprocess, 17.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.1ms\n",
            "Speed: 3.2ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 3.5ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 4.6ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 2.9ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.6ms\n",
            "Speed: 3.4ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.9ms\n",
            "Speed: 3.1ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.1ms\n",
            "Speed: 2.9ms preprocess, 19.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 4.8ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.3ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 3.2ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 18.8ms\n",
            "Speed: 2.6ms preprocess, 18.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.0ms\n",
            "Speed: 3.4ms preprocess, 17.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.5ms\n",
            "Speed: 2.7ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 17.8ms\n",
            "Speed: 2.7ms preprocess, 17.8ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 20.3ms\n",
            "Speed: 3.5ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.3ms\n",
            "Speed: 3.3ms preprocess, 16.3ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 3.5ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 5.3ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.4ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 3.7ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 5.0ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 3.1ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.6ms\n",
            "Speed: 3.0ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.9ms\n",
            "Speed: 3.1ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 3.0ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 2.9ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 3.6ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.2ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.1ms\n",
            "Speed: 3.1ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.7ms\n",
            "Speed: 2.8ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 3.8ms preprocess, 17.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.7ms\n",
            "Speed: 3.6ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 3.3ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.2ms\n",
            "Speed: 3.3ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.0ms\n",
            "Speed: 3.2ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.8ms\n",
            "Speed: 3.6ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 15.9ms\n",
            "Speed: 3.9ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 19.5ms\n",
            "Speed: 2.8ms preprocess, 19.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 19.1ms\n",
            "Speed: 3.9ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.1ms\n",
            "Speed: 3.1ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.5ms\n",
            "Speed: 3.4ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 3.1ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 4.0ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.0ms\n",
            "Speed: 3.5ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.0ms\n",
            "Speed: 3.3ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 2 guard rails, 16.4ms\n",
            "Speed: 3.4ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 19.1ms\n",
            "Speed: 3.1ms preprocess, 19.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.8ms preprocess, 16.1ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.1ms\n",
            "Speed: 2.9ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.9ms\n",
            "Speed: 4.6ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 18.0ms\n",
            "Speed: 3.3ms preprocess, 18.0ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.8ms\n",
            "Speed: 3.3ms preprocess, 16.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 15.8ms\n",
            "Speed: 3.6ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.7ms\n",
            "Speed: 3.9ms preprocess, 16.7ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.6ms\n",
            "Speed: 3.1ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.9ms\n",
            "Speed: 3.5ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 3.3ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.0ms\n",
            "Speed: 3.4ms preprocess, 17.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.7ms\n",
            "Speed: 3.1ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 19.5ms\n",
            "Speed: 7.2ms preprocess, 19.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.1ms\n",
            "Speed: 3.3ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 17.6ms\n",
            "Speed: 2.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 3.9ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 352x640 1 guard rail, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9hHeaxLRb2g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}